{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy Statistics\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Calculate descriptive statistics using `scipy.stats`\n",
    "2. Work with probability distributions (normal, uniform, exponential)\n",
    "3. Perform hypothesis testing (t-tests, chi-square tests)\n",
    "4. Calculate and interpret confidence intervals\n",
    "5. Apply statistical methods to real-world scientific data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction to scipy.stats\n",
    "\n",
    "The `scipy.stats` module provides a comprehensive collection of statistical functions, probability distributions, and statistical tests. It's essential for scientific computing and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"SciPy version:\", stats.__name__)\n",
    "print(\"Ready for statistical analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Descriptive Statistics\n",
    "\n",
    "Descriptive statistics summarize and describe the main features of a dataset. SciPy provides efficient functions for computing these measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data: daily temperatures in Celsius\n",
    "temperatures = np.random.normal(loc=20, scale=5, size=365)\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "print(\"Descriptive Statistics for Daily Temperatures\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Mean:              {np.mean(temperatures):.2f}°C\")\n",
    "print(f\"Median:            {np.median(temperatures):.2f}°C\")\n",
    "print(f\"Standard Deviation: {np.std(temperatures):.2f}°C\")\n",
    "print(f\"Variance:          {np.var(temperatures):.2f}\")\n",
    "print(f\"Min:               {np.min(temperatures):.2f}°C\")\n",
    "print(f\"Max:               {np.max(temperatures):.2f}°C\")\n",
    "print(f\"Range:             {np.ptp(temperatures):.2f}°C\")  # peak-to-peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Using scipy.stats.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive statistics with one function call\n",
    "result = stats.describe(temperatures)\n",
    "\n",
    "print(\"scipy.stats.describe() Output\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Number of observations: {result.nobs}\")\n",
    "print(f\"Minimum: {result.minmax[0]:.2f}°C\")\n",
    "print(f\"Maximum: {result.minmax[1]:.2f}°C\")\n",
    "print(f\"Mean: {result.mean:.2f}°C\")\n",
    "print(f\"Variance: {result.variance:.2f}\")\n",
    "print(f\"Skewness: {result.skewness:.4f}\")\n",
    "print(f\"Kurtosis: {result.kurtosis:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Skewness and Kurtosis\n",
    "\n",
    "- **Skewness**: Measures asymmetry of the distribution\n",
    "  - Positive skew: tail extends to the right\n",
    "  - Negative skew: tail extends to the left\n",
    "  - Zero: symmetric distribution\n",
    "\n",
    "- **Kurtosis**: Measures \"tailedness\" of the distribution\n",
    "  - Positive kurtosis: heavier tails than normal\n",
    "  - Negative kurtosis: lighter tails than normal\n",
    "  - Zero: similar to normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets with different skewness\n",
    "symmetric_data = np.random.normal(0, 1, 10000)\n",
    "right_skewed = np.random.exponential(2, 10000)\n",
    "left_skewed = -np.random.exponential(2, 10000)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "datasets = [\n",
    "    (symmetric_data, \"Symmetric (Normal)\"),\n",
    "    (right_skewed, \"Right Skewed (Exponential)\"),\n",
    "    (left_skewed, \"Left Skewed\")\n",
    "]\n",
    "\n",
    "for ax, (data, title) in zip(axes, datasets):\n",
    "    ax.hist(data, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "    ax.set_title(f\"{title}\\nSkewness: {stats.skew(data):.2f}\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Percentiles and Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentiles for temperature data\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "\n",
    "print(\"Temperature Percentiles\")\n",
    "print(\"=\" * 30)\n",
    "for p in percentiles:\n",
    "    value = np.percentile(temperatures, p)\n",
    "    print(f\"{p}th percentile: {value:.2f}°C\")\n",
    "\n",
    "# Interquartile range (IQR)\n",
    "q1 = np.percentile(temperatures, 25)\n",
    "q3 = np.percentile(temperatures, 75)\n",
    "iqr = q3 - q1\n",
    "print(f\"\\nInterquartile Range (IQR): {iqr:.2f}°C\")\n",
    "\n",
    "# Using scipy's IQR function\n",
    "print(f\"IQR (scipy.stats.iqr): {stats.iqr(temperatures):.2f}°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Mode and Other Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mode works best with discrete data\n",
    "# Let's use exam scores as an example\n",
    "exam_scores = np.random.choice([60, 65, 70, 75, 80, 85, 90, 95, 100], \n",
    "                               size=100, \n",
    "                               p=[0.05, 0.10, 0.15, 0.20, 0.20, 0.15, 0.10, 0.04, 0.01])\n",
    "\n",
    "mode_result = stats.mode(exam_scores, keepdims=True)\n",
    "print(f\"Mode: {mode_result.mode[0]} (appears {mode_result.count[0]} times)\")\n",
    "\n",
    "# Geometric mean (useful for growth rates)\n",
    "growth_rates = [1.05, 1.08, 1.02, 1.10, 1.03]  # 5%, 8%, 2%, 10%, 3% growth\n",
    "geo_mean = stats.gmean(growth_rates)\n",
    "print(f\"\\nGeometric mean of growth rates: {geo_mean:.4f}\")\n",
    "print(f\"Average annual growth rate: {(geo_mean - 1) * 100:.2f}%\")\n",
    "\n",
    "# Harmonic mean (useful for averaging rates)\n",
    "speeds = [60, 80, 70]  # mph for different segments of a trip\n",
    "harm_mean = stats.hmean(speeds)\n",
    "print(f\"\\nHarmonic mean of speeds: {harm_mean:.2f} mph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Probability Distributions\n",
    "\n",
    "SciPy provides a unified interface for working with many probability distributions. Each distribution has methods for:\n",
    "- `pdf(x)` / `pmf(x)`: Probability density/mass function\n",
    "- `cdf(x)`: Cumulative distribution function\n",
    "- `ppf(q)`: Percent point function (inverse of CDF)\n",
    "- `rvs(size)`: Random variates\n",
    "- `fit(data)`: Fit distribution parameters to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a normal distribution object\n",
    "# loc = mean, scale = standard deviation\n",
    "mu, sigma = 100, 15  # IQ scores: mean=100, std=15\n",
    "normal_dist = stats.norm(loc=mu, scale=sigma)\n",
    "\n",
    "# Generate random samples\n",
    "samples = normal_dist.rvs(size=1000)\n",
    "\n",
    "# Calculate probabilities\n",
    "print(\"IQ Score Analysis (Normal Distribution)\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# What's the probability of IQ < 85?\n",
    "prob_below_85 = normal_dist.cdf(85)\n",
    "print(f\"P(IQ < 85): {prob_below_85:.4f} ({prob_below_85*100:.2f}%)\")\n",
    "\n",
    "# What's the probability of IQ between 85 and 115?\n",
    "prob_85_to_115 = normal_dist.cdf(115) - normal_dist.cdf(85)\n",
    "print(f\"P(85 < IQ < 115): {prob_85_to_115:.4f} ({prob_85_to_115*100:.2f}%)\")\n",
    "\n",
    "# What IQ score is at the 95th percentile?\n",
    "iq_95th = normal_dist.ppf(0.95)\n",
    "print(f\"95th percentile IQ: {iq_95th:.1f}\")\n",
    "\n",
    "# Probability density at mean\n",
    "pdf_at_mean = normal_dist.pdf(mu)\n",
    "print(f\"PDF at mean (x=100): {pdf_at_mean:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the normal distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "x = np.linspace(mu - 4*sigma, mu + 4*sigma, 200)\n",
    "\n",
    "# PDF plot\n",
    "ax1 = axes[0]\n",
    "ax1.plot(x, normal_dist.pdf(x), 'b-', linewidth=2, label='PDF')\n",
    "ax1.fill_between(x, normal_dist.pdf(x), where=(x >= 85) & (x <= 115), \n",
    "                  alpha=0.3, label='P(85 < IQ < 115)')\n",
    "ax1.axvline(mu, color='red', linestyle='--', label=f'Mean = {mu}')\n",
    "ax1.set_xlabel('IQ Score')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title('Normal Distribution PDF')\n",
    "ax1.legend()\n",
    "\n",
    "# CDF plot\n",
    "ax2 = axes[1]\n",
    "ax2.plot(x, normal_dist.cdf(x), 'g-', linewidth=2)\n",
    "ax2.axhline(0.5, color='gray', linestyle=':', alpha=0.5)\n",
    "ax2.axvline(mu, color='red', linestyle='--', label=f'Mean = {mu}')\n",
    "ax2.set_xlabel('IQ Score')\n",
    "ax2.set_ylabel('Cumulative Probability')\n",
    "ax2.set_title('Normal Distribution CDF')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform distribution: all values equally likely within a range\n",
    "# scipy.stats.uniform uses loc (start) and scale (width)\n",
    "# For U(a, b): loc=a, scale=b-a\n",
    "\n",
    "a, b = 0, 10  # Random number between 0 and 10\n",
    "uniform_dist = stats.uniform(loc=a, scale=b-a)\n",
    "\n",
    "print(\"Uniform Distribution U(0, 10)\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"Mean: {uniform_dist.mean():.2f}\")\n",
    "print(f\"Variance: {uniform_dist.var():.2f}\")\n",
    "print(f\"Standard Deviation: {uniform_dist.std():.2f}\")\n",
    "\n",
    "# Probability of value between 3 and 7\n",
    "prob_3_to_7 = uniform_dist.cdf(7) - uniform_dist.cdf(3)\n",
    "print(f\"\\nP(3 < X < 7): {prob_3_to_7:.4f}\")\n",
    "\n",
    "# Generate samples\n",
    "uniform_samples = uniform_dist.rvs(size=10000)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.hist(uniform_samples, bins=50, density=True, alpha=0.7, \n",
    "        edgecolor='black', label='Samples')\n",
    "x = np.linspace(-1, 11, 100)\n",
    "ax.plot(x, uniform_dist.pdf(x), 'r-', linewidth=2, label='Theoretical PDF')\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Uniform Distribution U(0, 10)')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Exponential Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential distribution: models time between events\n",
    "# Often used for: time between customer arrivals, radioactive decay, etc.\n",
    "# scipy uses scale = 1/lambda (mean of distribution)\n",
    "\n",
    "# Example: Customer arrivals with average rate of 5 per hour\n",
    "rate = 5  # customers per hour (lambda)\n",
    "mean_time = 1/rate  # mean time between arrivals in hours\n",
    "\n",
    "exp_dist = stats.expon(scale=mean_time)\n",
    "\n",
    "print(\"Exponential Distribution (Customer Arrivals)\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Rate (lambda): {rate} customers/hour\")\n",
    "print(f\"Mean time between arrivals: {mean_time*60:.1f} minutes\")\n",
    "print(f\"Variance: {exp_dist.var()*3600:.2f} minutes^2\")\n",
    "\n",
    "# Probability of waiting more than 15 minutes (0.25 hours)\n",
    "prob_wait_15 = 1 - exp_dist.cdf(0.25)\n",
    "print(f\"\\nP(wait > 15 minutes): {prob_wait_15:.4f}\")\n",
    "\n",
    "# Probability of waiting less than 5 minutes\n",
    "prob_wait_5 = exp_dist.cdf(5/60)\n",
    "print(f\"P(wait < 5 minutes): {prob_wait_5:.4f}\")\n",
    "\n",
    "# Median wait time\n",
    "median_wait = exp_dist.ppf(0.5)\n",
    "print(f\"Median wait time: {median_wait*60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize exponential distribution\n",
    "x = np.linspace(0, 1, 200)  # 0 to 1 hour\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# PDF\n",
    "ax1 = axes[0]\n",
    "ax1.plot(x*60, exp_dist.pdf(x), 'b-', linewidth=2)\n",
    "ax1.fill_between(x*60, exp_dist.pdf(x), where=(x <= 0.25), alpha=0.3)\n",
    "ax1.axvline(15, color='red', linestyle='--', label='15 minutes')\n",
    "ax1.set_xlabel('Wait Time (minutes)')\n",
    "ax1.set_ylabel('Probability Density')\n",
    "ax1.set_title('Exponential Distribution PDF\\n(Time Between Customer Arrivals)')\n",
    "ax1.legend()\n",
    "\n",
    "# Survival function (1 - CDF)\n",
    "ax2 = axes[1]\n",
    "ax2.plot(x*60, 1 - exp_dist.cdf(x), 'g-', linewidth=2)\n",
    "ax2.axhline(0.5, color='gray', linestyle=':', alpha=0.5, label='50%')\n",
    "ax2.set_xlabel('Wait Time (minutes)')\n",
    "ax2.set_ylabel('Probability of Waiting Longer')\n",
    "ax2.set_title('Survival Function P(X > t)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Comparing Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Normal distributions with different parameters\n",
    "ax = axes[0, 0]\n",
    "x = np.linspace(-6, 6, 200)\n",
    "for mu, sigma in [(0, 1), (0, 2), (2, 1)]:\n",
    "    ax.plot(x, stats.norm.pdf(x, mu, sigma), \n",
    "            label=f'μ={mu}, σ={sigma}')\n",
    "ax.set_title('Normal Distributions')\n",
    "ax.legend()\n",
    "\n",
    "# Exponential distributions with different rates\n",
    "ax = axes[0, 1]\n",
    "x = np.linspace(0, 5, 200)\n",
    "for lam in [0.5, 1.0, 2.0]:\n",
    "    ax.plot(x, stats.expon.pdf(x, scale=1/lam), \n",
    "            label=f'λ={lam}')\n",
    "ax.set_title('Exponential Distributions')\n",
    "ax.legend()\n",
    "\n",
    "# Gamma distributions\n",
    "ax = axes[0, 2]\n",
    "x = np.linspace(0, 15, 200)\n",
    "for shape in [1, 2, 5]:\n",
    "    ax.plot(x, stats.gamma.pdf(x, shape), \n",
    "            label=f'k={shape}')\n",
    "ax.set_title('Gamma Distributions')\n",
    "ax.legend()\n",
    "\n",
    "# Beta distributions\n",
    "ax = axes[1, 0]\n",
    "x = np.linspace(0, 1, 200)\n",
    "for a, b in [(0.5, 0.5), (2, 5), (5, 2)]:\n",
    "    ax.plot(x, stats.beta.pdf(x, a, b), \n",
    "            label=f'α={a}, β={b}')\n",
    "ax.set_title('Beta Distributions')\n",
    "ax.legend()\n",
    "\n",
    "# Chi-square distributions\n",
    "ax = axes[1, 1]\n",
    "x = np.linspace(0, 20, 200)\n",
    "for df in [2, 4, 8]:\n",
    "    ax.plot(x, stats.chi2.pdf(x, df), \n",
    "            label=f'df={df}')\n",
    "ax.set_title('Chi-Square Distributions')\n",
    "ax.legend()\n",
    "\n",
    "# t-distributions\n",
    "ax = axes[1, 2]\n",
    "x = np.linspace(-4, 4, 200)\n",
    "ax.plot(x, stats.norm.pdf(x), 'k--', label='Normal', linewidth=2)\n",
    "for df in [1, 5, 30]:\n",
    "    ax.plot(x, stats.t.pdf(x, df), \n",
    "            label=f'df={df}')\n",
    "ax.set_title('Student\\'s t-Distributions')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Hypothesis Testing\n",
    "\n",
    "Hypothesis testing helps us make statistical decisions about populations based on sample data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 One-Sample t-Test\n",
    "\n",
    "Tests whether a sample mean differs significantly from a known population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Testing if a manufacturing process produces parts with correct mean weight\n",
    "# Specification: parts should weigh 50 grams\n",
    "\n",
    "# Sample of parts from the production line\n",
    "np.random.seed(123)\n",
    "sample_weights = np.random.normal(loc=50.5, scale=2, size=30)  # slightly off-target\n",
    "\n",
    "# Null hypothesis: μ = 50 grams\n",
    "# Alternative hypothesis: μ ≠ 50 grams (two-tailed test)\n",
    "target_weight = 50\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_stat, p_value = stats.ttest_1samp(sample_weights, target_weight)\n",
    "\n",
    "print(\"One-Sample t-Test: Manufacturing Quality Control\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Sample size: {len(sample_weights)}\")\n",
    "print(f\"Sample mean: {np.mean(sample_weights):.3f} grams\")\n",
    "print(f\"Sample std: {np.std(sample_weights, ddof=1):.3f} grams\")\n",
    "print(f\"Target mean: {target_weight} grams\")\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(f\"\\nConclusion: Reject H0 (p < {alpha})\")\n",
    "    print(\"The sample mean is significantly different from the target.\")\n",
    "else:\n",
    "    print(f\"\\nConclusion: Fail to reject H0 (p >= {alpha})\")\n",
    "    print(\"No significant difference from the target weight.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Two-Sample t-Test (Independent Samples)\n",
    "\n",
    "Tests whether two independent groups have different means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Comparing effectiveness of two treatments\n",
    "np.random.seed(456)\n",
    "\n",
    "# Treatment A: recovery time in days\n",
    "treatment_a = np.random.normal(loc=14, scale=3, size=25)\n",
    "\n",
    "# Treatment B: recovery time in days\n",
    "treatment_b = np.random.normal(loc=12, scale=3, size=25)\n",
    "\n",
    "# Perform two-sample t-test (assuming equal variances)\n",
    "t_stat, p_value = stats.ttest_ind(treatment_a, treatment_b)\n",
    "\n",
    "print(\"Two-Sample t-Test: Treatment Comparison\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Treatment A: n={len(treatment_a)}, mean={np.mean(treatment_a):.2f}, std={np.std(treatment_a, ddof=1):.2f}\")\n",
    "print(f\"Treatment B: n={len(treatment_b)}, mean={np.mean(treatment_b):.2f}, std={np.std(treatment_b, ddof=1):.2f}\")\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Welch's t-test (does not assume equal variances)\n",
    "t_stat_welch, p_value_welch = stats.ttest_ind(treatment_a, treatment_b, equal_var=False)\n",
    "print(f\"\\nWelch's t-test (unequal variances):\")\n",
    "print(f\"t-statistic: {t_stat_welch:.4f}\")\n",
    "print(f\"p-value: {p_value_welch:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the two groups\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Create box plots\n",
    "bp = ax.boxplot([treatment_a, treatment_b], labels=['Treatment A', 'Treatment B'],\n",
    "                patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "colors = ['lightblue', 'lightgreen']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "# Add individual points\n",
    "for i, (data, color) in enumerate(zip([treatment_a, treatment_b], ['blue', 'green']), 1):\n",
    "    x = np.random.normal(i, 0.04, size=len(data))\n",
    "    ax.scatter(x, data, alpha=0.6, color=color, s=30)\n",
    "\n",
    "ax.set_ylabel('Recovery Time (days)')\n",
    "ax.set_title(f'Treatment Comparison\\np-value = {p_value:.4f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Paired t-Test\n",
    "\n",
    "Tests whether the mean difference between paired observations is significantly different from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Before and after measurements (e.g., weight loss program)\n",
    "np.random.seed(789)\n",
    "\n",
    "n_subjects = 20\n",
    "weight_before = np.random.normal(loc=85, scale=10, size=n_subjects)\n",
    "# After program: average loss of 3 kg with some variation\n",
    "weight_loss = np.random.normal(loc=3, scale=2, size=n_subjects)\n",
    "weight_after = weight_before - weight_loss\n",
    "\n",
    "# Paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(weight_before, weight_after)\n",
    "\n",
    "print(\"Paired t-Test: Weight Loss Program Effectiveness\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Number of subjects: {n_subjects}\")\n",
    "print(f\"Mean weight before: {np.mean(weight_before):.2f} kg\")\n",
    "print(f\"Mean weight after: {np.mean(weight_after):.2f} kg\")\n",
    "print(f\"Mean difference: {np.mean(weight_before - weight_after):.2f} kg\")\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nConclusion: The weight loss is statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Chi-Square Test\n",
    "\n",
    "Tests for independence between categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Testing if customer satisfaction depends on product category\n",
    "# Contingency table: rows = categories, columns = satisfaction levels\n",
    "\n",
    "# Observed frequencies\n",
    "observed = np.array([\n",
    "    [50, 30, 20],   # Electronics: Satisfied, Neutral, Dissatisfied\n",
    "    [40, 35, 25],   # Clothing\n",
    "    [60, 25, 15],   # Home & Garden\n",
    "])\n",
    "\n",
    "# Perform chi-square test\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(\"Chi-Square Test of Independence\")\n",
    "print(\"=\" * 45)\n",
    "print(\"\\nObserved Frequencies:\")\n",
    "print(\"               Satisfied  Neutral  Dissatisfied\")\n",
    "categories = ['Electronics', 'Clothing', 'Home & Garden']\n",
    "for cat, row in zip(categories, observed):\n",
    "    print(f\"{cat:14} {row[0]:9} {row[1]:8} {row[2]:12}\")\n",
    "\n",
    "print(\"\\nExpected Frequencies (if independent):\")\n",
    "print(\"               Satisfied  Neutral  Dissatisfied\")\n",
    "for cat, row in zip(categories, expected):\n",
    "    print(f\"{cat:14} {row[0]:9.1f} {row[1]:8.1f} {row[2]:12.1f}\")\n",
    "\n",
    "print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nConclusion: Satisfaction depends on product category.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: No significant relationship between satisfaction and category.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Chi-Square Goodness of Fit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Testing if a die is fair\n",
    "# Expected: each face should appear 1/6 of the time\n",
    "\n",
    "# Observed frequencies from 600 rolls\n",
    "observed_rolls = np.array([92, 108, 97, 103, 95, 105])\n",
    "expected_rolls = np.array([100, 100, 100, 100, 100, 100])  # fair die\n",
    "\n",
    "chi2, p_value = stats.chisquare(observed_rolls, f_exp=expected_rolls)\n",
    "\n",
    "print(\"Chi-Square Goodness of Fit: Testing a Die\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"\\nTotal rolls: {sum(observed_rolls)}\")\n",
    "print(\"\\nFace   Observed  Expected\")\n",
    "for i in range(6):\n",
    "    print(f\"  {i+1}      {observed_rolls[i]:3}       {expected_rolls[i]}\")\n",
    "\n",
    "print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nConclusion: The die appears to be biased.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: No evidence that the die is biased.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Confidence Intervals\n",
    "\n",
    "Confidence intervals provide a range of plausible values for a population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Confidence Interval for the Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Estimating average battery life\n",
    "np.random.seed(42)\n",
    "battery_life = np.random.normal(loc=8.5, scale=1.2, size=50)  # hours\n",
    "\n",
    "# Calculate 95% confidence interval\n",
    "confidence = 0.95\n",
    "n = len(battery_life)\n",
    "mean = np.mean(battery_life)\n",
    "sem = stats.sem(battery_life)  # standard error of the mean\n",
    "\n",
    "# Using t-distribution (small sample or unknown population variance)\n",
    "ci = stats.t.interval(confidence, df=n-1, loc=mean, scale=sem)\n",
    "\n",
    "print(\"95% Confidence Interval for Battery Life\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Sample mean: {mean:.3f} hours\")\n",
    "print(f\"Standard deviation: {np.std(battery_life, ddof=1):.3f} hours\")\n",
    "print(f\"Standard error: {sem:.3f} hours\")\n",
    "print(f\"\\n95% Confidence Interval: ({ci[0]:.3f}, {ci[1]:.3f}) hours\")\n",
    "print(f\"Margin of error: ±{(ci[1] - ci[0])/2:.3f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare confidence intervals at different confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "\n",
    "print(\"Confidence Intervals at Different Levels\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "for i, conf in enumerate(confidence_levels):\n",
    "    ci = stats.t.interval(conf, df=n-1, loc=mean, scale=sem)\n",
    "    margin = (ci[1] - ci[0]) / 2\n",
    "    print(f\"{conf*100:.0f}% CI: ({ci[0]:.3f}, {ci[1]:.3f}), margin: ±{margin:.3f}\")\n",
    "    \n",
    "    # Plot\n",
    "    ax.errorbar(mean, i, xerr=margin, fmt='o', capsize=10, \n",
    "                capthick=2, markersize=10, label=f'{conf*100:.0f}% CI')\n",
    "\n",
    "ax.axvline(mean, color='red', linestyle='--', alpha=0.5)\n",
    "ax.set_yticks(range(len(confidence_levels)))\n",
    "ax.set_yticklabels([f'{c*100:.0f}%' for c in confidence_levels])\n",
    "ax.set_xlabel('Battery Life (hours)')\n",
    "ax.set_ylabel('Confidence Level')\n",
    "ax.set_title('Confidence Intervals at Different Levels')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Confidence Interval for Proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Estimating proportion of defective products\n",
    "n_samples = 200\n",
    "n_defective = 12\n",
    "p_hat = n_defective / n_samples\n",
    "\n",
    "# Using normal approximation (Wilson score interval is more accurate for small p)\n",
    "# Standard error for proportion\n",
    "se_prop = np.sqrt(p_hat * (1 - p_hat) / n_samples)\n",
    "\n",
    "# 95% CI using normal distribution\n",
    "z = stats.norm.ppf(0.975)  # z-score for 95% CI\n",
    "ci_lower = p_hat - z * se_prop\n",
    "ci_upper = p_hat + z * se_prop\n",
    "\n",
    "print(\"95% Confidence Interval for Defect Rate\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Sample size: {n_samples}\")\n",
    "print(f\"Number of defects: {n_defective}\")\n",
    "print(f\"Sample proportion: {p_hat:.4f} ({p_hat*100:.2f}%)\")\n",
    "print(f\"Standard error: {se_prop:.4f}\")\n",
    "print(f\"\\n95% CI: ({ci_lower:.4f}, {ci_upper:.4f})\")\n",
    "print(f\"        ({ci_lower*100:.2f}%, {ci_upper*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Sample Size Determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How large a sample do we need for a desired margin of error?\n",
    "\n",
    "def sample_size_for_mean(margin_of_error, std_dev, confidence=0.95):\n",
    "    \"\"\"Calculate required sample size for estimating a mean.\"\"\"\n",
    "    z = stats.norm.ppf((1 + confidence) / 2)\n",
    "    n = ((z * std_dev) / margin_of_error) ** 2\n",
    "    return int(np.ceil(n))\n",
    "\n",
    "def sample_size_for_proportion(margin_of_error, p=0.5, confidence=0.95):\n",
    "    \"\"\"Calculate required sample size for estimating a proportion.\"\"\"\n",
    "    z = stats.norm.ppf((1 + confidence) / 2)\n",
    "    n = (z**2 * p * (1 - p)) / margin_of_error**2\n",
    "    return int(np.ceil(n))\n",
    "\n",
    "# Example: Battery life study\n",
    "print(\"Sample Size Calculations\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# For mean estimation\n",
    "desired_margin = 0.2  # hours\n",
    "estimated_std = 1.2   # hours\n",
    "n_needed = sample_size_for_mean(desired_margin, estimated_std)\n",
    "print(f\"\\nFor mean (margin = ±{desired_margin} hours, σ = {estimated_std}):\")\n",
    "print(f\"Required sample size: {n_needed}\")\n",
    "\n",
    "# For proportion estimation\n",
    "desired_margin_prop = 0.03  # 3 percentage points\n",
    "n_needed_prop = sample_size_for_proportion(desired_margin_prop)\n",
    "print(f\"\\nFor proportion (margin = ±{desired_margin_prop*100}%, p = 0.5):\")\n",
    "print(f\"Required sample size: {n_needed_prop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "Practice what you've learned with these exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Descriptive Statistics\n",
    "\n",
    "A scientist measures the length of 50 fish from a lake (in cm). Calculate:\n",
    "1. Mean, median, and standard deviation\n",
    "2. Skewness and kurtosis\n",
    "3. The 10th and 90th percentiles\n",
    "4. Create a histogram with the mean and median marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fish length data (in cm)\n",
    "np.random.seed(100)\n",
    "fish_lengths = np.concatenate([\n",
    "    np.random.normal(25, 3, 35),  # Main population\n",
    "    np.random.normal(35, 2, 15)   # Larger fish\n",
    "])\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# 1. Basic statistics\n",
    "print(\"Descriptive Statistics for Fish Lengths\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Mean: {np.mean(fish_lengths):.2f} cm\")\n",
    "print(f\"Median: {np.median(fish_lengths):.2f} cm\")\n",
    "print(f\"Standard Deviation: {np.std(fish_lengths, ddof=1):.2f} cm\")\n",
    "\n",
    "# 2. Skewness and kurtosis\n",
    "print(f\"\\nSkewness: {stats.skew(fish_lengths):.4f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(fish_lengths):.4f}\")\n",
    "\n",
    "# 3. Percentiles\n",
    "p10 = np.percentile(fish_lengths, 10)\n",
    "p90 = np.percentile(fish_lengths, 90)\n",
    "print(f\"\\n10th percentile: {p10:.2f} cm\")\n",
    "print(f\"90th percentile: {p90:.2f} cm\")\n",
    "\n",
    "# 4. Histogram\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(fish_lengths, bins=15, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(np.mean(fish_lengths), color='red', linestyle='--', \n",
    "           linewidth=2, label=f'Mean = {np.mean(fish_lengths):.2f}')\n",
    "ax.axvline(np.median(fish_lengths), color='green', linestyle='-', \n",
    "           linewidth=2, label=f'Median = {np.median(fish_lengths):.2f}')\n",
    "ax.set_xlabel('Fish Length (cm)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Fish Lengths')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Working with Distributions\n",
    "\n",
    "The time between customer arrivals at a bank follows an exponential distribution with a mean of 3 minutes.\n",
    "\n",
    "1. Create the distribution object\n",
    "2. Calculate the probability of waiting more than 5 minutes\n",
    "3. Calculate the probability of waiting between 2 and 4 minutes\n",
    "4. Find the median wait time\n",
    "5. Generate 1000 random samples and verify the theoretical mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# 1. Create exponential distribution with mean = 3 minutes\n",
    "mean_time = 3\n",
    "exp_dist = stats.expon(scale=mean_time)\n",
    "\n",
    "print(\"Bank Customer Wait Time Analysis\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Distribution: Exponential with mean = {mean_time} minutes\")\n",
    "\n",
    "# 2. P(X > 5)\n",
    "prob_more_than_5 = 1 - exp_dist.cdf(5)\n",
    "print(f\"\\nP(wait > 5 min): {prob_more_than_5:.4f} ({prob_more_than_5*100:.2f}%)\")\n",
    "\n",
    "# 3. P(2 < X < 4)\n",
    "prob_2_to_4 = exp_dist.cdf(4) - exp_dist.cdf(2)\n",
    "print(f\"P(2 < wait < 4 min): {prob_2_to_4:.4f} ({prob_2_to_4*100:.2f}%)\")\n",
    "\n",
    "# 4. Median wait time\n",
    "median = exp_dist.ppf(0.5)\n",
    "print(f\"Median wait time: {median:.2f} minutes\")\n",
    "\n",
    "# 5. Simulate and verify\n",
    "samples = exp_dist.rvs(size=1000)\n",
    "print(f\"\\nSimulation (n=1000):\")\n",
    "print(f\"Sample mean: {np.mean(samples):.2f} minutes\")\n",
    "print(f\"Theoretical mean: {mean_time} minutes\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(samples, bins=30, density=True, alpha=0.7, edgecolor='black', label='Samples')\n",
    "x = np.linspace(0, 15, 100)\n",
    "ax.plot(x, exp_dist.pdf(x), 'r-', linewidth=2, label='Theoretical PDF')\n",
    "ax.axvline(median, color='green', linestyle='--', label=f'Median = {median:.2f}')\n",
    "ax.set_xlabel('Wait Time (minutes)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Customer Wait Time Distribution')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Hypothesis Testing\n",
    "\n",
    "A pharmaceutical company claims their new drug reduces blood pressure by an average of 10 mmHg. In a clinical trial, 25 patients showed the following reductions:\n",
    "\n",
    "1. Perform a one-sample t-test to check if the mean reduction differs from 10 mmHg\n",
    "2. Calculate and interpret the 95% confidence interval\n",
    "3. What conclusion would you draw at α = 0.05?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blood pressure reductions (mmHg)\n",
    "np.random.seed(42)\n",
    "bp_reductions = np.random.normal(loc=8.5, scale=4, size=25)\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Claimed reduction\n",
    "claimed_reduction = 10\n",
    "\n",
    "# Basic statistics\n",
    "n = len(bp_reductions)\n",
    "mean_reduction = np.mean(bp_reductions)\n",
    "std_reduction = np.std(bp_reductions, ddof=1)\n",
    "sem = stats.sem(bp_reductions)\n",
    "\n",
    "print(\"Blood Pressure Reduction Analysis\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Sample mean: {mean_reduction:.2f} mmHg\")\n",
    "print(f\"Sample std: {std_reduction:.2f} mmHg\")\n",
    "print(f\"Claimed reduction: {claimed_reduction} mmHg\")\n",
    "\n",
    "# 1. One-sample t-test\n",
    "t_stat, p_value = stats.ttest_1samp(bp_reductions, claimed_reduction)\n",
    "print(f\"\\nt-statistic: {t_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# 2. 95% confidence interval\n",
    "ci = stats.t.interval(0.95, df=n-1, loc=mean_reduction, scale=sem)\n",
    "print(f\"\\n95% CI: ({ci[0]:.2f}, {ci[1]:.2f}) mmHg\")\n",
    "\n",
    "# 3. Conclusion\n",
    "print(\"\\n\" + \"=\" * 45)\n",
    "print(\"Conclusion:\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"At α = 0.05, we reject the null hypothesis (p = {p_value:.4f}).\")\n",
    "    print(f\"The actual reduction ({mean_reduction:.2f} mmHg) is significantly\")\n",
    "    print(f\"different from the claimed {claimed_reduction} mmHg.\")\n",
    "else:\n",
    "    print(f\"At α = 0.05, we fail to reject the null hypothesis.\")\n",
    "\n",
    "# Check if 10 is in the CI\n",
    "if ci[0] <= claimed_reduction <= ci[1]:\n",
    "    print(f\"\\nNote: {claimed_reduction} mmHg is within the 95% CI.\")\n",
    "else:\n",
    "    print(f\"\\nNote: {claimed_reduction} mmHg is outside the 95% CI.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Chi-Square Test\n",
    "\n",
    "A researcher wants to know if there's a relationship between exercise frequency and sleep quality. Survey data from 300 people is given below:\n",
    "\n",
    "1. Perform a chi-square test of independence\n",
    "2. Calculate the expected frequencies\n",
    "3. Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed frequencies\n",
    "# Rows: Exercise frequency (Never, 1-2x/week, 3+x/week)\n",
    "# Columns: Sleep quality (Poor, Fair, Good)\n",
    "observed = np.array([\n",
    "    [40, 30, 20],   # Never exercise\n",
    "    [25, 45, 40],   # 1-2x/week\n",
    "    [15, 35, 50],   # 3+x/week\n",
    "])\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Labels for better output\n",
    "exercise_levels = ['Never', '1-2x/week', '3+x/week']\n",
    "sleep_quality = ['Poor', 'Fair', 'Good']\n",
    "\n",
    "# 1 & 2. Chi-square test\n",
    "chi2, p_value, dof, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(\"Chi-Square Test: Exercise Frequency vs Sleep Quality\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\nObserved Frequencies:\")\n",
    "print(f\"{'Exercise':<12} {'Poor':>8} {'Fair':>8} {'Good':>8} {'Total':>8}\")\n",
    "print(\"-\" * 48)\n",
    "for i, ex in enumerate(exercise_levels):\n",
    "    print(f\"{ex:<12} {observed[i,0]:>8} {observed[i,1]:>8} {observed[i,2]:>8} {sum(observed[i]):>8}\")\n",
    "print(\"-\" * 48)\n",
    "print(f\"{'Total':<12} {observed[:,0].sum():>8} {observed[:,1].sum():>8} {observed[:,2].sum():>8} {observed.sum():>8}\")\n",
    "\n",
    "print(\"\\nExpected Frequencies (if independent):\")\n",
    "print(f\"{'Exercise':<12} {'Poor':>8} {'Fair':>8} {'Good':>8}\")\n",
    "print(\"-\" * 40)\n",
    "for i, ex in enumerate(exercise_levels):\n",
    "    print(f\"{ex:<12} {expected[i,0]:>8.1f} {expected[i,1]:>8.1f} {expected[i,2]:>8.1f}\")\n",
    "\n",
    "print(f\"\\nChi-square statistic: {chi2:.4f}\")\n",
    "print(f\"Degrees of freedom: {dof}\")\n",
    "print(f\"p-value: {p_value:.6f}\")\n",
    "\n",
    "# 3. Interpretation\n",
    "print(\"\\n\" + \"=\" * 55)\n",
    "print(\"Interpretation:\")\n",
    "if p_value < 0.05:\n",
    "    print(f\"At α = 0.05, we reject the null hypothesis of independence.\")\n",
    "    print(f\"There IS a significant relationship between exercise frequency\")\n",
    "    print(f\"and sleep quality (χ² = {chi2:.2f}, p = {p_value:.4f}).\")\n",
    "    print(f\"\\nLooking at the data, people who exercise more frequently\")\n",
    "    print(f\"tend to report better sleep quality.\")\n",
    "else:\n",
    "    print(f\"At α = 0.05, we fail to reject the null hypothesis.\")\n",
    "    print(f\"No significant relationship between exercise and sleep quality.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Confidence Intervals and Sample Size\n",
    "\n",
    "A quality control engineer wants to estimate the average lifespan of light bulbs.\n",
    "\n",
    "1. From a sample of 40 bulbs with mean = 1200 hours and std = 150 hours, calculate the 99% CI\n",
    "2. If we want the margin of error to be at most ±20 hours (95% CI), how many bulbs should we test?\n",
    "3. How does the margin of error change as confidence level increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Given data\n",
    "n = 40\n",
    "mean = 1200\n",
    "std = 150\n",
    "sem = std / np.sqrt(n)\n",
    "\n",
    "print(\"Light Bulb Lifespan Analysis\")\n",
    "print(\"=\" * 45)\n",
    "print(f\"Sample size: {n}\")\n",
    "print(f\"Sample mean: {mean} hours\")\n",
    "print(f\"Sample std: {std} hours\")\n",
    "print(f\"Standard error: {sem:.2f} hours\")\n",
    "\n",
    "# 1. 99% Confidence Interval\n",
    "ci_99 = stats.t.interval(0.99, df=n-1, loc=mean, scale=sem)\n",
    "margin_99 = (ci_99[1] - ci_99[0]) / 2\n",
    "print(f\"\\n99% CI: ({ci_99[0]:.2f}, {ci_99[1]:.2f}) hours\")\n",
    "print(f\"Margin of error: ±{margin_99:.2f} hours\")\n",
    "\n",
    "# 2. Sample size for margin of error ±20 hours\n",
    "desired_margin = 20\n",
    "z = stats.norm.ppf(0.975)  # Using z for large sample approximation\n",
    "n_required = ((z * std) / desired_margin) ** 2\n",
    "print(f\"\\nFor margin of error ≤ ±{desired_margin} hours (95% CI):\")\n",
    "print(f\"Required sample size: {int(np.ceil(n_required))} bulbs\")\n",
    "\n",
    "# 3. Margin of error vs confidence level\n",
    "print(\"\\nMargin of Error at Different Confidence Levels:\")\n",
    "conf_levels = [0.80, 0.90, 0.95, 0.99]\n",
    "for conf in conf_levels:\n",
    "    ci = stats.t.interval(conf, df=n-1, loc=mean, scale=sem)\n",
    "    margin = (ci[1] - ci[0]) / 2\n",
    "    print(f\"{conf*100:>5.0f}% CI: margin = ±{margin:.2f} hours\")\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "margins = [(stats.t.interval(c, df=n-1, loc=mean, scale=sem)[1] - \n",
    "            stats.t.interval(c, df=n-1, loc=mean, scale=sem)[0]) / 2 \n",
    "           for c in np.linspace(0.50, 0.99, 50)]\n",
    "ax.plot(np.linspace(50, 99, 50), margins, 'b-', linewidth=2)\n",
    "ax.set_xlabel('Confidence Level (%)')\n",
    "ax.set_ylabel('Margin of Error (hours)')\n",
    "ax.set_title('Trade-off: Confidence Level vs Margin of Error')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **Descriptive Statistics**\n",
    "   - Central tendency: mean, median, mode\n",
    "   - Dispersion: variance, standard deviation, IQR\n",
    "   - Shape: skewness and kurtosis\n",
    "   - `scipy.stats.describe()` for comprehensive statistics\n",
    "\n",
    "2. **Probability Distributions**\n",
    "   - Normal distribution for symmetric continuous data\n",
    "   - Uniform distribution for equally likely outcomes\n",
    "   - Exponential distribution for time between events\n",
    "   - Key methods: `pdf()`, `cdf()`, `ppf()`, `rvs()`, `fit()`\n",
    "\n",
    "3. **Hypothesis Testing**\n",
    "   - One-sample t-test: comparing sample mean to population mean\n",
    "   - Two-sample t-test: comparing two independent groups\n",
    "   - Paired t-test: comparing paired observations\n",
    "   - Chi-square test: testing independence between categorical variables\n",
    "\n",
    "4. **Confidence Intervals**\n",
    "   - Interpretation: range of plausible values for population parameter\n",
    "   - Effect of sample size and confidence level\n",
    "   - Sample size determination for desired precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue your SciPy journey with the next notebook:\n",
    "\n",
    "**[02_interpolation_fitting.ipynb](02_interpolation_fitting.ipynb)** - Learn about interpolation, curve fitting, and splines for data approximation and smoothing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
