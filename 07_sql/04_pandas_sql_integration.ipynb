{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and SQL Integration\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. Load SQL query results directly into Pandas DataFrames using `pd.read_sql()`\n",
    "2. Understand the difference between `pd.read_sql_query()` and `pd.read_sql_table()`\n",
    "3. Write DataFrames to SQL database tables using `df.to_sql()`\n",
    "4. Know when to use SQL vs Pandas for data manipulation\n",
    "5. Build practical workflows combining SQL and Pandas strengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Setup: Create the Company Database\n",
    "\n",
    "First, let's create our familiar company database with departments, employees, and projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check pandas version\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "# Remove existing database for a fresh start\n",
    "db_path = 'company.db'\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "\n",
    "# Create database and connection\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create tables\n",
    "cursor.executescript('''\n",
    "    CREATE TABLE departments (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL UNIQUE,\n",
    "        budget REAL DEFAULT 0\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE employees (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        department_id INTEGER,\n",
    "        salary REAL,\n",
    "        hire_date TEXT,\n",
    "        FOREIGN KEY (department_id) REFERENCES departments(id)\n",
    "    );\n",
    "    \n",
    "    CREATE TABLE projects (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        department_id INTEGER,\n",
    "        start_date TEXT,\n",
    "        end_date TEXT,\n",
    "        FOREIGN KEY (department_id) REFERENCES departments(id)\n",
    "    );\n",
    "''')\n",
    "\n",
    "print(\"Tables created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert sample data\n",
    "departments = [\n",
    "    (1, 'Engineering', 500000),\n",
    "    (2, 'Marketing', 300000),\n",
    "    (3, 'Sales', 400000),\n",
    "    (4, 'HR', 200000),\n",
    "    (5, 'Finance', 350000)\n",
    "]\n",
    "\n",
    "employees = [\n",
    "    (1, 'Alice Johnson', 1, 95000, '2020-03-15'),\n",
    "    (2, 'Bob Smith', 1, 85000, '2021-06-01'),\n",
    "    (3, 'Carol Williams', 1, 92000, '2019-08-20'),\n",
    "    (4, 'David Brown', 2, 78000, '2022-01-10'),\n",
    "    (5, 'Eva Martinez', 2, 82000, '2021-03-25'),\n",
    "    (6, 'Frank Wilson', 3, 88000, '2020-11-05'),\n",
    "    (7, 'Grace Lee', 3, 91000, '2019-05-12'),\n",
    "    (8, 'Henry Taylor', 4, 65000, '2022-07-18'),\n",
    "    (9, 'Ivy Chen', 1, 105000, '2018-02-28'),\n",
    "    (10, 'Jack Anderson', 3, 95000, '2020-09-14'),\n",
    "    (11, 'Karen White', 2, 75000, '2023-02-01'),\n",
    "    (12, 'Leo Garcia', 5, 89000, '2021-11-20'),\n",
    "    (13, 'Mia Davis', 4, 62000, '2023-04-15'),\n",
    "    (14, 'Nathan Moore', 5, 94000, '2019-07-01'),\n",
    "    (15, 'Olivia Clark', 1, 110000, '2017-09-10')\n",
    "]\n",
    "\n",
    "projects = [\n",
    "    (1, 'Cloud Migration', 1, '2024-01-15', '2024-06-30'),\n",
    "    (2, 'Brand Refresh', 2, '2024-02-01', '2024-04-30'),\n",
    "    (3, 'Q2 Sales Campaign', 3, '2024-04-01', '2024-06-30'),\n",
    "    (4, 'Mobile App v2.0', 1, '2024-03-01', '2024-09-30'),\n",
    "    (5, 'Employee Portal', 4, '2024-02-15', '2024-05-31'),\n",
    "    (6, 'Data Analytics Platform', 1, '2024-05-01', '2024-12-31'),\n",
    "    (7, 'Customer Retention', 3, '2024-03-15', '2024-08-15'),\n",
    "    (8, 'Budget Planning System', 5, '2024-01-01', '2024-03-31')\n",
    "]\n",
    "\n",
    "cursor.executemany('INSERT INTO departments VALUES (?, ?, ?)', departments)\n",
    "cursor.executemany('INSERT INTO employees VALUES (?, ?, ?, ?, ?)', employees)\n",
    "cursor.executemany('INSERT INTO projects VALUES (?, ?, ?, ?, ?)', projects)\n",
    "conn.commit()\n",
    "\n",
    "print(f\"Inserted: {len(departments)} departments, {len(employees)} employees, {len(projects)} projects\")\n",
    "print(\"Database setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Loading SQL Data into Pandas with pd.read_sql()\n",
    "\n",
    "Pandas provides several functions to read data from SQL databases:\n",
    "\n",
    "| Function | Description |\n",
    "|----------|-------------|\n",
    "| `pd.read_sql()` | General purpose - works with queries or table names |\n",
    "| `pd.read_sql_query()` | Execute a SQL query and return results |\n",
    "| `pd.read_sql_table()` | Read an entire table (requires SQLAlchemy) |\n",
    "\n",
    "For SQLite with the `sqlite3` module, `pd.read_sql()` and `pd.read_sql_query()` are the most useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage: pd.read_sql()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an entire table into a DataFrame\n",
    "df_employees = pd.read_sql('SELECT * FROM employees', conn)\n",
    "\n",
    "print(\"Employees DataFrame:\")\n",
    "print(f\"Shape: {df_employees.shape}\")\n",
    "print(f\"Columns: {list(df_employees.columns)}\")\n",
    "print()\n",
    "df_employees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all departments\n",
    "df_departments = pd.read_sql('SELECT * FROM departments', conn)\n",
    "df_departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with a specific query (filtering in SQL)\n",
    "df_high_earners = pd.read_sql('''\n",
    "    SELECT name, salary, hire_date \n",
    "    FROM employees \n",
    "    WHERE salary > 90000\n",
    "    ORDER BY salary DESC\n",
    "''', conn)\n",
    "\n",
    "print(\"High Earners (>$90k):\")\n",
    "df_high_earners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Parameters in Queries\n",
    "\n",
    "Use the `params` argument to safely pass values to your query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using parameters to filter safely\n",
    "min_salary = 80000\n",
    "department_id = 1\n",
    "\n",
    "df_filtered = pd.read_sql('''\n",
    "    SELECT name, salary \n",
    "    FROM employees \n",
    "    WHERE salary >= ? AND department_id = ?\n",
    "''', conn, params=(min_salary, department_id))\n",
    "\n",
    "print(f\"Engineering employees earning >= ${min_salary:,}:\")\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Index Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the 'id' column as the DataFrame index\n",
    "df_emp_indexed = pd.read_sql('SELECT * FROM employees', conn, index_col='id')\n",
    "\n",
    "print(\"Employees with 'id' as index:\")\n",
    "df_emp_indexed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can access rows by employee ID\n",
    "print(\"Employee with ID 5:\")\n",
    "print(df_emp_indexed.loc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Dates Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without date parsing - hire_date is a string\n",
    "df_no_parse = pd.read_sql('SELECT * FROM employees', conn)\n",
    "print(\"Without date parsing:\")\n",
    "print(f\"hire_date dtype: {df_no_parse['hire_date'].dtype}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With date parsing - hire_date becomes datetime\n",
    "df_with_dates = pd.read_sql(\n",
    "    'SELECT * FROM employees', \n",
    "    conn, \n",
    "    parse_dates=['hire_date']\n",
    ")\n",
    "\n",
    "print(\"With date parsing:\")\n",
    "print(f\"hire_date dtype: {df_with_dates['hire_date'].dtype}\")\n",
    "print()\n",
    "\n",
    "# Now we can use datetime operations\n",
    "print(\"Hire year distribution:\")\n",
    "print(df_with_dates['hire_date'].dt.year.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading JOINed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load employees with department names (JOIN in SQL)\n",
    "df_emp_dept = pd.read_sql('''\n",
    "    SELECT \n",
    "        e.id,\n",
    "        e.name,\n",
    "        d.name as department,\n",
    "        e.salary,\n",
    "        e.hire_date\n",
    "    FROM employees e\n",
    "    JOIN departments d ON e.department_id = d.id\n",
    "    ORDER BY d.name, e.salary DESC\n",
    "''', conn, parse_dates=['hire_date'])\n",
    "\n",
    "print(\"Employees with Department Names:\")\n",
    "df_emp_dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. pd.read_sql_query() vs pd.read_sql_table()\n",
    "\n",
    "### pd.read_sql_query()\n",
    "\n",
    "Execute a SQL query and return the results as a DataFrame. This is functionally identical to `pd.read_sql()` when passing a query string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_query() - explicitly for queries\n",
    "df_query = pd.read_sql_query(\n",
    "    'SELECT name, salary FROM employees WHERE salary > 85000',\n",
    "    conn\n",
    ")\n",
    "\n",
    "print(\"Using read_sql_query():\")\n",
    "df_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pd.read_sql_table()\n",
    "\n",
    "Reads an entire table. **Note**: This requires SQLAlchemy, which we'll demonstrate but won't use extensively since we're focusing on the built-in sqlite3 module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_sql_table() requires SQLAlchemy\n",
    "# Here's how you would use it:\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine('sqlite:///company.db')\n",
    "# df_table = pd.read_sql_table('employees', engine)\n",
    "\n",
    "# For sqlite3, use read_sql() with 'SELECT * FROM table_name' instead:\n",
    "df_all_employees = pd.read_sql('SELECT * FROM employees', conn)\n",
    "print(\"Full employees table:\")\n",
    "print(f\"Shape: {df_all_employees.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Writing DataFrames to SQL with df.to_sql()\n",
    "\n",
    "The `to_sql()` method writes a DataFrame to a SQL database table.\n",
    "\n",
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to write\n",
    "new_employees = pd.DataFrame({\n",
    "    'name': ['Peter Parker', 'Diana Prince', 'Bruce Wayne'],\n",
    "    'department_id': [1, 3, 5],\n",
    "    'salary': [72000, 98000, 150000],\n",
    "    'hire_date': ['2024-01-15', '2024-02-01', '2024-01-02']\n",
    "})\n",
    "\n",
    "print(\"New employees to add:\")\n",
    "new_employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a NEW table (not the existing employees table)\n",
    "new_employees.to_sql(\n",
    "    'new_hires',           # Table name\n",
    "    conn,                   # Connection\n",
    "    if_exists='replace',    # What to do if table exists\n",
    "    index=False             # Don't write the DataFrame index\n",
    ")\n",
    "\n",
    "print(\"Data written to 'new_hires' table!\")\n",
    "\n",
    "# Verify\n",
    "df_verify = pd.read_sql('SELECT * FROM new_hires', conn)\n",
    "df_verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if_exists Parameter\n",
    "\n",
    "Controls behavior when the table already exists:\n",
    "\n",
    "| Value | Behavior |\n",
    "|-------|----------|\n",
    "| `'fail'` | Raise an error (default) |\n",
    "| `'replace'` | Drop and recreate the table |\n",
    "| `'append'` | Add rows to existing table |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append more data to the new_hires table\n",
    "more_employees = pd.DataFrame({\n",
    "    'name': ['Clark Kent', 'Barry Allen'],\n",
    "    'department_id': [2, 1],\n",
    "    'salary': [85000, 78000],\n",
    "    'hire_date': ['2024-03-01', '2024-03-15']\n",
    "})\n",
    "\n",
    "more_employees.to_sql(\n",
    "    'new_hires',\n",
    "    conn,\n",
    "    if_exists='append',  # Add to existing table\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"Appended more employees!\")\n",
    "\n",
    "# Verify - should now have 5 rows\n",
    "df_all_new = pd.read_sql('SELECT * FROM new_hires', conn)\n",
    "print(f\"Total rows: {len(df_all_new)}\")\n",
    "df_all_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing with Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with meaningful index\n",
    "dept_summary = pd.DataFrame({\n",
    "    'total_budget': [500000, 300000, 400000],\n",
    "    'employee_count': [5, 3, 3]\n",
    "}, index=['Engineering', 'Marketing', 'Sales'])\n",
    "dept_summary.index.name = 'department'\n",
    "\n",
    "print(\"Department summary (with index):\")\n",
    "print(dept_summary)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write WITH the index\n",
    "dept_summary.to_sql(\n",
    "    'department_summary',\n",
    "    conn,\n",
    "    if_exists='replace',\n",
    "    index=True  # Include the index as a column\n",
    ")\n",
    "\n",
    "# Verify - index becomes a column\n",
    "df_summary = pd.read_sql('SELECT * FROM department_summary', conn)\n",
    "print(\"Written to SQL (index becomes 'department' column):\")\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with specific types\n",
    "products = pd.DataFrame({\n",
    "    'product_name': ['Widget', 'Gadget', 'Gizmo'],\n",
    "    'price': [29.99, 49.99, 19.99],\n",
    "    'quantity': [100, 50, 200],\n",
    "    'in_stock': [True, True, False]\n",
    "})\n",
    "\n",
    "# Write with explicit SQL types\n",
    "products.to_sql(\n",
    "    'products',\n",
    "    conn,\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    dtype={\n",
    "        'product_name': 'TEXT',\n",
    "        'price': 'REAL',\n",
    "        'quantity': 'INTEGER',\n",
    "        'in_stock': 'INTEGER'  # SQLite stores booleans as 0/1\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check the table schema\n",
    "cursor.execute('PRAGMA table_info(products)')\n",
    "print(\"Products table schema:\")\n",
    "for col in cursor.fetchall():\n",
    "    print(f\"  {col[1]}: {col[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. When to Use SQL vs Pandas\n",
    "\n",
    "Both SQL and Pandas can perform many of the same operations. Here's guidance on when to use each:\n",
    "\n",
    "### Use SQL When:\n",
    "\n",
    "| Scenario | Why SQL |\n",
    "|----------|--------|\n",
    "| **Filtering large datasets** | Database engine filters before transferring data |\n",
    "| **Joining multiple tables** | SQL engines optimize joins efficiently |\n",
    "| **Aggregating at scale** | Aggregate in database, transfer only results |\n",
    "| **Data lives in database** | Avoid loading unnecessary data into memory |\n",
    "\n",
    "### Use Pandas When:\n",
    "\n",
    "| Scenario | Why Pandas |\n",
    "|----------|------------|\n",
    "| **Complex transformations** | More flexible data manipulation |\n",
    "| **Time series operations** | Superior datetime handling |\n",
    "| **Statistical analysis** | Rich statistical functions |\n",
    "| **Data visualization prep** | Easy integration with matplotlib, seaborn |\n",
    "| **Iterative exploration** | Quick feedback loop |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Let SQL do the heavy lifting, Pandas for analysis\n",
    "\n",
    "# BAD: Load all data, then filter in Pandas\n",
    "# df_all = pd.read_sql('SELECT * FROM employees', conn)\n",
    "# df_filtered = df_all[df_all['salary'] > 90000]\n",
    "\n",
    "# GOOD: Filter in SQL, get only what you need\n",
    "df_filtered = pd.read_sql('''\n",
    "    SELECT e.*, d.name as department_name\n",
    "    FROM employees e\n",
    "    JOIN departments d ON e.department_id = d.id\n",
    "    WHERE e.salary > 90000\n",
    "''', conn)\n",
    "\n",
    "print(\"Filtered data from SQL:\")\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: SQL for aggregation, Pandas for presentation\n",
    "\n",
    "# Get aggregated data from SQL\n",
    "df_stats = pd.read_sql('''\n",
    "    SELECT \n",
    "        d.name as department,\n",
    "        COUNT(*) as employees,\n",
    "        AVG(e.salary) as avg_salary,\n",
    "        MIN(e.salary) as min_salary,\n",
    "        MAX(e.salary) as max_salary\n",
    "    FROM employees e\n",
    "    JOIN departments d ON e.department_id = d.id\n",
    "    GROUP BY d.id, d.name\n",
    "''', conn)\n",
    "\n",
    "# Use Pandas for formatting and additional calculations\n",
    "df_stats['salary_range'] = df_stats['max_salary'] - df_stats['min_salary']\n",
    "df_stats['avg_salary'] = df_stats['avg_salary'].round(2)\n",
    "\n",
    "print(\"Department Salary Statistics:\")\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Practical Workflow: SQL for Filtering/Joining, Pandas for Analysis\n",
    "\n",
    "Let's walk through a complete analysis workflow combining both tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use SQL to Extract and Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a comprehensive dataset with SQL\n",
    "df_analysis = pd.read_sql('''\n",
    "    SELECT \n",
    "        e.id as employee_id,\n",
    "        e.name as employee_name,\n",
    "        e.salary,\n",
    "        e.hire_date,\n",
    "        d.id as department_id,\n",
    "        d.name as department,\n",
    "        d.budget as department_budget\n",
    "    FROM employees e\n",
    "    JOIN departments d ON e.department_id = d.id\n",
    "''', conn, parse_dates=['hire_date'])\n",
    "\n",
    "print(f\"Loaded {len(df_analysis)} employee records\")\n",
    "df_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use Pandas for Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add calculated columns with Pandas\n",
    "from datetime import date\n",
    "\n",
    "# Years of service\n",
    "df_analysis['years_of_service'] = (\n",
    "    (pd.Timestamp.today() - df_analysis['hire_date']).dt.days / 365\n",
    ").round(1)\n",
    "\n",
    "# Salary as percentage of department budget\n",
    "df_analysis['salary_pct_of_budget'] = (\n",
    "    df_analysis['salary'] / df_analysis['department_budget'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Salary category\n",
    "df_analysis['salary_level'] = pd.cut(\n",
    "    df_analysis['salary'],\n",
    "    bins=[0, 70000, 90000, float('inf')],\n",
    "    labels=['Entry', 'Mid', 'Senior']\n",
    ")\n",
    "\n",
    "df_analysis[['employee_name', 'salary', 'years_of_service', 'salary_pct_of_budget', 'salary_level']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use Pandas for Aggregation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze by department\n",
    "dept_analysis = df_analysis.groupby('department').agg({\n",
    "    'employee_id': 'count',\n",
    "    'salary': ['mean', 'std', 'min', 'max'],\n",
    "    'years_of_service': 'mean',\n",
    "    'department_budget': 'first'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "dept_analysis.columns = ['_'.join(col).strip() for col in dept_analysis.columns.values]\n",
    "dept_analysis = dept_analysis.rename(columns={\n",
    "    'employee_id_count': 'num_employees',\n",
    "    'salary_mean': 'avg_salary',\n",
    "    'salary_std': 'salary_std_dev',\n",
    "    'salary_min': 'min_salary',\n",
    "    'salary_max': 'max_salary',\n",
    "    'years_of_service_mean': 'avg_tenure',\n",
    "    'department_budget_first': 'budget'\n",
    "})\n",
    "\n",
    "print(\"Department Analysis:\")\n",
    "dept_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salary level distribution by department\n",
    "salary_dist = pd.crosstab(\n",
    "    df_analysis['department'], \n",
    "    df_analysis['salary_level'],\n",
    "    margins=True\n",
    ")\n",
    "\n",
    "print(\"Salary Level Distribution by Department:\")\n",
    "salary_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Write Results Back to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the department analysis back to the database\n",
    "dept_analysis.to_sql(\n",
    "    'department_analysis',\n",
    "    conn,\n",
    "    if_exists='replace',\n",
    "    index=True  # Keep department as a column\n",
    ")\n",
    "\n",
    "print(\"Department analysis saved to database!\")\n",
    "\n",
    "# Verify\n",
    "pd.read_sql('SELECT * FROM department_analysis', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create a Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine SQL and Pandas for a final report\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPANY WORKFORCE ANALYSIS REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Company-wide stats\n",
    "print(\"\\n### Company Overview ###\")\n",
    "print(f\"Total Employees: {len(df_analysis)}\")\n",
    "print(f\"Total Salary Expense: ${df_analysis['salary'].sum():,.0f}\")\n",
    "print(f\"Average Salary: ${df_analysis['salary'].mean():,.0f}\")\n",
    "print(f\"Average Tenure: {df_analysis['years_of_service'].mean():.1f} years\")\n",
    "\n",
    "# Top earners\n",
    "print(\"\\n### Top 5 Earners ###\")\n",
    "top_earners = df_analysis.nlargest(5, 'salary')[['employee_name', 'department', 'salary']]\n",
    "for _, row in top_earners.iterrows():\n",
    "    print(f\"  {row['employee_name']} ({row['department']}): ${row['salary']:,.0f}\")\n",
    "\n",
    "# Longest tenured\n",
    "print(\"\\n### Longest Tenured Employees ###\")\n",
    "veterans = df_analysis.nlargest(3, 'years_of_service')[['employee_name', 'years_of_service', 'department']]\n",
    "for _, row in veterans.iterrows():\n",
    "    print(f\"  {row['employee_name']} ({row['department']}): {row['years_of_service']:.1f} years\")\n",
    "\n",
    "# Department with highest avg salary\n",
    "print(\"\\n### Highest Paying Department ###\")\n",
    "highest_paying = dept_analysis['avg_salary'].idxmax()\n",
    "print(f\"  {highest_paying}: ${dept_analysis.loc[highest_paying, 'avg_salary']:,.0f} average\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Basic SQL to DataFrame\n",
    "\n",
    "Load all projects from the database into a DataFrame, parsing the `start_date` and `end_date` columns as dates. Display the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "df_projects = pd.read_sql(\n",
    "    'SELECT * FROM projects',\n",
    "    conn,\n",
    "    parse_dates=['start_date', 'end_date']\n",
    ")\n",
    "\n",
    "print(\"Projects DataFrame:\")\n",
    "print(f\"Date columns dtypes:\")\n",
    "print(f\"  start_date: {df_projects['start_date'].dtype}\")\n",
    "print(f\"  end_date: {df_projects['end_date'].dtype}\")\n",
    "print()\n",
    "df_projects\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Parameterized Query\n",
    "\n",
    "Write a function that takes a department name and minimum salary as parameters, and returns a DataFrame of employees matching those criteria. Use parameterized queries for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "def get_employees_by_dept_salary(dept_name: str, min_salary: float) -> pd.DataFrame:\n",
    "    \"\"\"Get employees from a department earning at least min_salary.\"\"\"\n",
    "    query = '''\n",
    "        SELECT e.name, e.salary, d.name as department\n",
    "        FROM employees e\n",
    "        JOIN departments d ON e.department_id = d.id\n",
    "        WHERE d.name = ? AND e.salary >= ?\n",
    "        ORDER BY e.salary DESC\n",
    "    '''\n",
    "    return pd.read_sql(query, conn, params=(dept_name, min_salary))\n",
    "\n",
    "# Test the function\n",
    "result = get_employees_by_dept_salary('Engineering', 90000)\n",
    "print(\"Engineering employees earning >= $90k:\")\n",
    "result\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: DataFrame to SQL\n",
    "\n",
    "Create a DataFrame containing quarterly sales data (Q1-Q4) for 3 products. Write it to a new table called 'quarterly_sales'. Then read it back to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Create the DataFrame\n",
    "quarterly_sales = pd.DataFrame({\n",
    "    'product': ['Widget', 'Widget', 'Widget', 'Widget',\n",
    "                'Gadget', 'Gadget', 'Gadget', 'Gadget',\n",
    "                'Gizmo', 'Gizmo', 'Gizmo', 'Gizmo'],\n",
    "    'quarter': ['Q1', 'Q2', 'Q3', 'Q4'] * 3,\n",
    "    'sales': [10000, 12000, 15000, 18000,\n",
    "              8000, 9500, 11000, 12500,\n",
    "              5000, 6000, 7500, 9000]\n",
    "})\n",
    "\n",
    "# Write to database\n",
    "quarterly_sales.to_sql(\n",
    "    'quarterly_sales',\n",
    "    conn,\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")\n",
    "print(\"Written to 'quarterly_sales' table!\")\n",
    "\n",
    "# Read back to verify\n",
    "df_verify = pd.read_sql('SELECT * FROM quarterly_sales', conn)\n",
    "print(f\"\\nVerification ({len(df_verify)} rows):\")\n",
    "df_verify\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Combined Workflow\n",
    "\n",
    "1. Use SQL to get all employees with their department names and project counts\n",
    "2. Use Pandas to calculate the salary percentile of each employee within their department\n",
    "3. Display the top 3 employees by percentile in each department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Step 1: SQL query to get employees with departments\n",
    "df = pd.read_sql('''\n",
    "    SELECT \n",
    "        e.name,\n",
    "        e.salary,\n",
    "        d.name as department\n",
    "    FROM employees e\n",
    "    JOIN departments d ON e.department_id = d.id\n",
    "''', conn)\n",
    "\n",
    "# Step 2: Calculate salary percentile within department\n",
    "df['salary_percentile'] = df.groupby('department')['salary'].transform(\n",
    "    lambda x: (x.rank(pct=True) * 100).round(1)\n",
    ")\n",
    "\n",
    "# Step 3: Get top 3 by percentile in each department\n",
    "top_by_dept = df.sort_values(['department', 'salary_percentile'], ascending=[True, False])\n",
    "top_by_dept = top_by_dept.groupby('department').head(3)\n",
    "\n",
    "print(\"Top 3 Earners by Percentile in Each Department:\")\n",
    "for dept in top_by_dept['department'].unique():\n",
    "    print(f\"\\n{dept}:\")\n",
    "    dept_data = top_by_dept[top_by_dept['department'] == dept]\n",
    "    for _, row in dept_data.iterrows():\n",
    "        print(f\"  {row['name']}: ${row['salary']:,.0f} ({row['salary_percentile']}th percentile)\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Analysis Pipeline\n",
    "\n",
    "Create a complete analysis pipeline that:\n",
    "1. Loads project data with department names from SQL\n",
    "2. Calculates project duration in days using Pandas\n",
    "3. Groups by department to find average project duration\n",
    "4. Saves the results back to a new 'project_stats' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Step 1: Load projects with department names\n",
    "df_projects = pd.read_sql('''\n",
    "    SELECT \n",
    "        p.name as project,\n",
    "        d.name as department,\n",
    "        p.start_date,\n",
    "        p.end_date\n",
    "    FROM projects p\n",
    "    JOIN departments d ON p.department_id = d.id\n",
    "''', conn, parse_dates=['start_date', 'end_date'])\n",
    "\n",
    "# Step 2: Calculate project duration\n",
    "df_projects['duration_days'] = (df_projects['end_date'] - df_projects['start_date']).dt.days\n",
    "\n",
    "print(\"Projects with Duration:\")\n",
    "print(df_projects[['project', 'department', 'duration_days']])\n",
    "\n",
    "# Step 3: Group by department\n",
    "project_stats = df_projects.groupby('department').agg({\n",
    "    'project': 'count',\n",
    "    'duration_days': ['mean', 'min', 'max']\n",
    "}).round(1)\n",
    "\n",
    "project_stats.columns = ['num_projects', 'avg_duration', 'min_duration', 'max_duration']\n",
    "\n",
    "print(\"\\nProject Statistics by Department:\")\n",
    "print(project_stats)\n",
    "\n",
    "# Step 4: Save to database\n",
    "project_stats.to_sql('project_stats', conn, if_exists='replace', index=True)\n",
    "print(\"\\nSaved to 'project_stats' table!\")\n",
    "\n",
    "# Verify\n",
    "pd.read_sql('SELECT * FROM project_stats', conn)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "### Loading Data from SQL\n",
    "- `pd.read_sql(query, conn)` - Execute query and return DataFrame\n",
    "- `pd.read_sql_query()` - Same as read_sql for queries\n",
    "- Use `params` for safe parameterized queries\n",
    "- Use `parse_dates` to automatically convert date columns\n",
    "- Use `index_col` to set the DataFrame index\n",
    "\n",
    "### Writing Data to SQL\n",
    "- `df.to_sql(table_name, conn)` - Write DataFrame to table\n",
    "- `if_exists`: 'fail' (default), 'replace', or 'append'\n",
    "- `index=False` to exclude DataFrame index\n",
    "- `dtype` to specify SQL column types\n",
    "\n",
    "### Best Practices\n",
    "1. **Use SQL for**: Filtering, joining, aggregating large datasets\n",
    "2. **Use Pandas for**: Complex transformations, time series, statistics\n",
    "3. **Workflow**: SQL extracts and joins -> Pandas transforms and analyzes -> Write results back\n",
    "\n",
    "### Key Functions\n",
    "\n",
    "| Function | Purpose |\n",
    "|----------|--------|\n",
    "| `pd.read_sql()` | Load SQL query results to DataFrame |\n",
    "| `pd.read_sql_query()` | Execute SQL query (explicit) |\n",
    "| `df.to_sql()` | Write DataFrame to SQL table |\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the SQL in Python module! You now know how to:\n",
    "- Create and manage SQLite databases\n",
    "- Perform CRUD operations (Create, Read, Update, Delete)\n",
    "- Write advanced queries with JOINs and subqueries\n",
    "- Integrate SQL with Pandas for powerful data analysis workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection and remove database file\n",
    "conn.close()\n",
    "\n",
    "if os.path.exists('company.db'):\n",
    "    os.remove('company.db')\n",
    "    print(\"Database file removed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
