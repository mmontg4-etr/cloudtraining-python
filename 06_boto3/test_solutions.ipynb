{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 Test: Boto3 and AWS - SOLUTIONS\n",
    "\n",
    "This test covers the fundamental concepts and practical skills for working with AWS services using the Boto3 library in Python.\n",
    "\n",
    "## Topics Covered:\n",
    "- AWS fundamentals and setup\n",
    "- S3 operations (buckets, objects, upload/download)\n",
    "- DynamoDB operations\n",
    "- Lambda and SQS/SNS basics\n",
    "- Practical patterns (error handling, pagination)\n",
    "\n",
    "## Instructions:\n",
    "1. Read each question carefully\n",
    "2. Write your solution in the provided code cell\n",
    "3. Since AWS credentials may not be available, many questions use mocking or are conceptual\n",
    "4. For mock-based questions, use `unittest.mock` or `moto` library patterns\n",
    "5. Run your code to verify it works (where applicable)\n",
    "\n",
    "## Grading:\n",
    "- Questions 1-4: Fundamentals (easier)\n",
    "- Questions 5-8: Intermediate\n",
    "- Questions 9-12: Advanced\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports for this test\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError, BotoCoreError\n",
    "from unittest.mock import Mock, MagicMock, patch\n",
    "import json\n",
    "from typing import Dict, List, Optional, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: AWS Fundamentals and Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Understanding Boto3 Clients vs Resources (Easy)\n",
    "\n",
    "Boto3 provides two ways to interact with AWS services: **clients** and **resources**.\n",
    "\n",
    "**Task:** Write a function called `explain_boto3_interfaces()` that returns a dictionary explaining:\n",
    "1. What a boto3 client is and when to use it\n",
    "2. What a boto3 resource is and when to use it\n",
    "3. One advantage of each approach\n",
    "\n",
    "The function should return a dictionary with keys: `'client'`, `'resource'`, `'client_advantage'`, `'resource_advantage'`\n",
    "\n",
    "**Example output structure:**\n",
    "```python\n",
    "{\n",
    "    'client': 'description...',\n",
    "    'resource': 'description...',\n",
    "    'client_advantage': 'advantage...',\n",
    "    'resource_advantage': 'advantage...'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 1\n",
    "\n",
    "def explain_boto3_interfaces() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Explain the differences between boto3 clients and resources.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with explanations of client and resource interfaces.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'client': (\n",
    "            \"A low-level service interface that maps directly to AWS service APIs. \"\n",
    "            \"Clients provide 1:1 mapping to service operations and return dictionary \"\n",
    "            \"responses. Use clients when you need access to all service operations or \"\n",
    "            \"when resources don't support the operation you need.\"\n",
    "        ),\n",
    "        'resource': (\n",
    "            \"A higher-level, object-oriented interface that represents AWS resources \"\n",
    "            \"as Python objects. Resources provide a more Pythonic way to interact with \"\n",
    "            \"AWS services. Use resources when you want cleaner, more readable code and \"\n",
    "            \"when working with services that have good resource support (S3, EC2, DynamoDB).\"\n",
    "        ),\n",
    "        'client_advantage': (\n",
    "            \"Complete API coverage - clients provide access to ALL service operations, \"\n",
    "            \"including newer features that may not yet be available in resources.\"\n",
    "        ),\n",
    "        'resource_advantage': (\n",
    "            \"More Pythonic and readable code - resources allow chaining operations, \"\n",
    "            \"automatic pagination through collections, and working with objects rather \"\n",
    "            \"than raw dictionaries.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "# Test the function\n",
    "result = explain_boto3_interfaces()\n",
    "for key, value in result.items():\n",
    "    print(f\"\\n{key.upper()}:\")\n",
    "    print(f\"  {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: AWS Credential Configuration (Easy)\n",
    "\n",
    "AWS credentials can be configured in multiple ways with a specific precedence order.\n",
    "\n",
    "**Task:** Write a function called `get_credential_precedence()` that returns a list of the credential sources boto3 checks, **in order of precedence** (first checked to last checked).\n",
    "\n",
    "Include at least 5 credential sources.\n",
    "\n",
    "**Hint:** Think about environment variables, config files, IAM roles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 2\n",
    "\n",
    "def get_credential_precedence() -> List[str]:\n",
    "    \"\"\"\n",
    "    Return the order of precedence for AWS credential sources.\n",
    "    \n",
    "    Boto3 checks these sources in order, using the first valid credentials found.\n",
    "    \n",
    "    Returns:\n",
    "        List of credential sources in order of precedence (first checked to last).\n",
    "    \"\"\"\n",
    "    return [\n",
    "        \"1. Passing credentials as parameters when creating clients/resources\",\n",
    "        \"2. Passing credentials as parameters when creating a Session\",\n",
    "        \"3. Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN)\",\n",
    "        \"4. Shared credentials file (~/.aws/credentials)\",\n",
    "        \"5. AWS config file (~/.aws/config)\",\n",
    "        \"6. Assume Role provider (from config file)\",\n",
    "        \"7. Boto2 config file (/etc/boto.cfg and ~/.boto)\",\n",
    "        \"8. IAM Role for Amazon EC2 (instance metadata service)\",\n",
    "        \"9. IAM Role for ECS tasks (container credentials)\",\n",
    "        \"10. IAM Identity Center (SSO) credentials\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# Test the function\n",
    "precedence = get_credential_precedence()\n",
    "print(\"AWS Credential Precedence (highest to lowest):\")\n",
    "print(\"=\" * 50)\n",
    "for source in precedence:\n",
    "    print(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: S3 Operations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Creating an S3 Bucket (Easy)\n",
    "\n",
    "**Task:** Write a function called `create_s3_bucket(bucket_name: str, region: str) -> dict` that:\n",
    "1. Creates an S3 bucket with the given name in the specified region\n",
    "2. Handles the special case for `us-east-1` region (no LocationConstraint needed)\n",
    "3. Returns the response from the create_bucket call\n",
    "4. Includes proper error handling for `ClientError`\n",
    "\n",
    "**Note:** You can use mocking to test this function. The function itself should contain the real boto3 code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 3\n",
    "\n",
    "def create_s3_bucket(bucket_name: str, region: str) -> dict:\n",
    "    \"\"\"\n",
    "    Create an S3 bucket in the specified region.\n",
    "    \n",
    "    Args:\n",
    "        bucket_name: The name of the bucket to create (must be globally unique).\n",
    "        region: The AWS region where the bucket should be created.\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing the response from create_bucket call,\n",
    "        or error information if the operation failed.\n",
    "        \n",
    "    Raises:\n",
    "        ClientError: If the bucket creation fails.\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3', region_name=region)\n",
    "    \n",
    "    try:\n",
    "        # us-east-1 is special - it doesn't accept LocationConstraint\n",
    "        if region == 'us-east-1':\n",
    "            response = s3_client.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            response = s3_client.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={\n",
    "                    'LocationConstraint': region\n",
    "                }\n",
    "            )\n",
    "        return response\n",
    "    \n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        error_message = e.response['Error']['Message']\n",
    "        print(f\"Error creating bucket: {error_code} - {error_message}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.client') as mock_client:\n",
    "    mock_s3 = MagicMock()\n",
    "    mock_client.return_value = mock_s3\n",
    "    mock_s3.create_bucket.return_value = {'Location': '/my-test-bucket'}\n",
    "    \n",
    "    # Test us-east-1 (no LocationConstraint)\n",
    "    result = create_s3_bucket('my-test-bucket', 'us-east-1')\n",
    "    print(f\"us-east-1 result: {result}\")\n",
    "    mock_s3.create_bucket.assert_called_with(Bucket='my-test-bucket')\n",
    "    \n",
    "    # Test other region (with LocationConstraint)\n",
    "    mock_s3.reset_mock()\n",
    "    result = create_s3_bucket('my-test-bucket', 'eu-west-1')\n",
    "    print(f\"eu-west-1 result: {result}\")\n",
    "    mock_s3.create_bucket.assert_called_with(\n",
    "        Bucket='my-test-bucket',\n",
    "        CreateBucketConfiguration={'LocationConstraint': 'eu-west-1'}\n",
    "    )\n",
    "    \n",
    "print(\"\\nAll tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Upload and Download Operations (Easy)\n",
    "\n",
    "**Task:** Write two functions:\n",
    "\n",
    "1. `upload_file_to_s3(file_path: str, bucket: str, object_key: str) -> bool`\n",
    "   - Uploads a local file to S3\n",
    "   - Returns True on success, False on failure\n",
    "   - Handles errors gracefully\n",
    "\n",
    "2. `download_file_from_s3(bucket: str, object_key: str, local_path: str) -> bool`\n",
    "   - Downloads an S3 object to a local file\n",
    "   - Returns True on success, False on failure\n",
    "   - Handles errors gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 4\n",
    "\n",
    "def upload_file_to_s3(file_path: str, bucket: str, object_key: str) -> bool:\n",
    "    \"\"\"\n",
    "    Upload a local file to an S3 bucket.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the local file to upload.\n",
    "        bucket: Name of the S3 bucket.\n",
    "        object_key: The key (path) for the object in S3.\n",
    "        \n",
    "    Returns:\n",
    "        True if upload was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        s3_client.upload_file(file_path, bucket, object_key)\n",
    "        print(f\"Successfully uploaded {file_path} to s3://{bucket}/{object_key}\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Local file not found: {file_path}\")\n",
    "        return False\n",
    "    except ClientError as e:\n",
    "        print(f\"Error uploading file: {e.response['Error']['Message']}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_file_from_s3(bucket: str, object_key: str, local_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Download an S3 object to a local file.\n",
    "    \n",
    "    Args:\n",
    "        bucket: Name of the S3 bucket.\n",
    "        object_key: The key (path) of the object in S3.\n",
    "        local_path: Path where the file should be saved locally.\n",
    "        \n",
    "    Returns:\n",
    "        True if download was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        s3_client.download_file(bucket, object_key, local_path)\n",
    "        print(f\"Successfully downloaded s3://{bucket}/{object_key} to {local_path}\")\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        if error_code == '404':\n",
    "            print(f\"Error: Object not found: s3://{bucket}/{object_key}\")\n",
    "        else:\n",
    "            print(f\"Error downloading file: {e.response['Error']['Message']}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.client') as mock_client:\n",
    "    mock_s3 = MagicMock()\n",
    "    mock_client.return_value = mock_s3\n",
    "    \n",
    "    # Test successful upload\n",
    "    result = upload_file_to_s3('/path/to/file.txt', 'my-bucket', 'uploads/file.txt')\n",
    "    print(f\"Upload result: {result}\")\n",
    "    \n",
    "    # Test successful download\n",
    "    result = download_file_from_s3('my-bucket', 'uploads/file.txt', '/local/file.txt')\n",
    "    print(f\"Download result: {result}\")\n",
    "    \n",
    "    # Test failed upload (ClientError)\n",
    "    mock_s3.upload_file.side_effect = ClientError(\n",
    "        {'Error': {'Code': 'AccessDenied', 'Message': 'Access Denied'}},\n",
    "        'upload_file'\n",
    "    )\n",
    "    result = upload_file_to_s3('/path/to/file.txt', 'my-bucket', 'uploads/file.txt')\n",
    "    print(f\"Failed upload result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Generate Presigned URLs (Intermediate)\n",
    "\n",
    "Presigned URLs allow temporary access to private S3 objects without requiring AWS credentials.\n",
    "\n",
    "**Task:** Write a function called `generate_presigned_url(bucket: str, object_key: str, expiration: int = 3600, operation: str = 'get_object') -> Optional[str]` that:\n",
    "1. Generates a presigned URL for either downloading (`get_object`) or uploading (`put_object`)\n",
    "2. Uses the specified expiration time in seconds (default 1 hour)\n",
    "3. Returns the URL string or None if generation fails\n",
    "4. Handles both `get_object` and `put_object` operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 5\n",
    "\n",
    "def generate_presigned_url(\n",
    "    bucket: str,\n",
    "    object_key: str,\n",
    "    expiration: int = 3600,\n",
    "    operation: str = 'get_object'\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Generate a presigned URL for S3 operations.\n",
    "    \n",
    "    Args:\n",
    "        bucket: Name of the S3 bucket.\n",
    "        object_key: The key (path) of the object in S3.\n",
    "        expiration: URL expiration time in seconds (default: 3600 = 1 hour).\n",
    "        operation: Either 'get_object' for download or 'put_object' for upload.\n",
    "        \n",
    "    Returns:\n",
    "        The presigned URL string, or None if generation fails.\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If operation is not 'get_object' or 'put_object'.\n",
    "    \"\"\"\n",
    "    valid_operations = ['get_object', 'put_object']\n",
    "    if operation not in valid_operations:\n",
    "        raise ValueError(f\"Operation must be one of {valid_operations}\")\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    try:\n",
    "        url = s3_client.generate_presigned_url(\n",
    "            ClientMethod=operation,\n",
    "            Params={\n",
    "                'Bucket': bucket,\n",
    "                'Key': object_key\n",
    "            },\n",
    "            ExpiresIn=expiration\n",
    "        )\n",
    "        return url\n",
    "    except ClientError as e:\n",
    "        print(f\"Error generating presigned URL: {e.response['Error']['Message']}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.client') as mock_client:\n",
    "    mock_s3 = MagicMock()\n",
    "    mock_client.return_value = mock_s3\n",
    "    mock_s3.generate_presigned_url.return_value = 'https://bucket.s3.amazonaws.com/key?signature=xxx'\n",
    "    \n",
    "    # Test get_object (download)\n",
    "    url = generate_presigned_url('my-bucket', 'files/document.pdf')\n",
    "    print(f\"Download URL: {url}\")\n",
    "    \n",
    "    # Test put_object (upload) with custom expiration\n",
    "    url = generate_presigned_url('my-bucket', 'uploads/new-file.txt', expiration=7200, operation='put_object')\n",
    "    print(f\"Upload URL: {url}\")\n",
    "    \n",
    "    # Verify the calls\n",
    "    calls = mock_s3.generate_presigned_url.call_args_list\n",
    "    print(f\"\\nNumber of presigned URL calls: {len(calls)}\")\n",
    "    \n",
    "    # Test invalid operation\n",
    "    try:\n",
    "        generate_presigned_url('my-bucket', 'key', operation='invalid_op')\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nCaught expected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: DynamoDB Operations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: DynamoDB CRUD Operations (Intermediate)\n",
    "\n",
    "**Task:** Create a class called `DynamoDBManager` that provides basic CRUD operations for a DynamoDB table.\n",
    "\n",
    "The class should have:\n",
    "1. `__init__(self, table_name: str)` - Initialize with table name and create DynamoDB resource\n",
    "2. `put_item(self, item: Dict) -> bool` - Add or update an item\n",
    "3. `get_item(self, key: Dict) -> Optional[Dict]` - Retrieve an item by its key\n",
    "4. `delete_item(self, key: Dict) -> bool` - Delete an item by its key\n",
    "5. `scan_table(self) -> List[Dict]` - Return all items in the table\n",
    "\n",
    "All methods should include proper error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 6\n",
    "\n",
    "class DynamoDBManager:\n",
    "    \"\"\"\n",
    "    A manager class for basic DynamoDB CRUD operations.\n",
    "    \n",
    "    Provides a simplified interface for common DynamoDB operations\n",
    "    including put, get, delete, and scan.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, table_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the DynamoDB manager.\n",
    "        \n",
    "        Args:\n",
    "            table_name: Name of the DynamoDB table to manage.\n",
    "        \"\"\"\n",
    "        self.table_name = table_name\n",
    "        self.dynamodb = boto3.resource('dynamodb')\n",
    "        self.table = self.dynamodb.Table(table_name)\n",
    "    \n",
    "    def put_item(self, item: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Add or update an item in the table.\n",
    "        \n",
    "        Args:\n",
    "            item: Dictionary containing the item attributes.\n",
    "                  Must include the primary key attribute(s).\n",
    "                  \n",
    "        Returns:\n",
    "            True if successful, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.table.put_item(Item=item)\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            print(f\"Error putting item: {e.response['Error']['Message']}\")\n",
    "            return False\n",
    "    \n",
    "    def get_item(self, key: Dict) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve an item by its primary key.\n",
    "        \n",
    "        Args:\n",
    "            key: Dictionary containing the primary key attribute(s).\n",
    "            \n",
    "        Returns:\n",
    "            The item as a dictionary if found, None otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.table.get_item(Key=key)\n",
    "            return response.get('Item')\n",
    "        except ClientError as e:\n",
    "            print(f\"Error getting item: {e.response['Error']['Message']}\")\n",
    "            return None\n",
    "    \n",
    "    def delete_item(self, key: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Delete an item by its primary key.\n",
    "        \n",
    "        Args:\n",
    "            key: Dictionary containing the primary key attribute(s).\n",
    "            \n",
    "        Returns:\n",
    "            True if successful, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.table.delete_item(Key=key)\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            print(f\"Error deleting item: {e.response['Error']['Message']}\")\n",
    "            return False\n",
    "    \n",
    "    def scan_table(self) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Scan and return all items in the table.\n",
    "        \n",
    "        Note: Scan reads every item in the table. Use with caution\n",
    "        on large tables as it can be slow and expensive.\n",
    "        \n",
    "        Returns:\n",
    "            List of all items in the table.\n",
    "        \"\"\"\n",
    "        items = []\n",
    "        try:\n",
    "            response = self.table.scan()\n",
    "            items.extend(response.get('Items', []))\n",
    "            \n",
    "            # Handle pagination\n",
    "            while 'LastEvaluatedKey' in response:\n",
    "                response = self.table.scan(\n",
    "                    ExclusiveStartKey=response['LastEvaluatedKey']\n",
    "                )\n",
    "                items.extend(response.get('Items', []))\n",
    "                \n",
    "            return items\n",
    "        except ClientError as e:\n",
    "            print(f\"Error scanning table: {e.response['Error']['Message']}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.resource') as mock_resource:\n",
    "    mock_dynamodb = MagicMock()\n",
    "    mock_table = MagicMock()\n",
    "    mock_resource.return_value = mock_dynamodb\n",
    "    mock_dynamodb.Table.return_value = mock_table\n",
    "    \n",
    "    # Create manager\n",
    "    manager = DynamoDBManager('Users')\n",
    "    \n",
    "    # Test put_item\n",
    "    result = manager.put_item({'user_id': '123', 'name': 'John', 'email': 'john@example.com'})\n",
    "    print(f\"Put item result: {result}\")\n",
    "    \n",
    "    # Test get_item\n",
    "    mock_table.get_item.return_value = {\n",
    "        'Item': {'user_id': '123', 'name': 'John', 'email': 'john@example.com'}\n",
    "    }\n",
    "    item = manager.get_item({'user_id': '123'})\n",
    "    print(f\"Get item result: {item}\")\n",
    "    \n",
    "    # Test delete_item\n",
    "    result = manager.delete_item({'user_id': '123'})\n",
    "    print(f\"Delete item result: {result}\")\n",
    "    \n",
    "    # Test scan_table\n",
    "    mock_table.scan.return_value = {\n",
    "        'Items': [\n",
    "            {'user_id': '1', 'name': 'Alice'},\n",
    "            {'user_id': '2', 'name': 'Bob'}\n",
    "        ]\n",
    "    }\n",
    "    items = manager.scan_table()\n",
    "    print(f\"Scan result: {items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: DynamoDB Query with Filter (Intermediate)\n",
    "\n",
    "**Task:** Write a function called `query_users_by_status(table_name: str, status: str, min_age: int) -> List[Dict]` that:\n",
    "1. Queries a DynamoDB table named `Users` with a GSI (Global Secondary Index) on `status`\n",
    "2. Filters results to only include users with age >= min_age\n",
    "3. Uses KeyConditionExpression for the status query\n",
    "4. Uses FilterExpression for the age filter\n",
    "5. Returns the list of matching items\n",
    "\n",
    "**Assume the table has:**\n",
    "- Primary key: `user_id` (String)\n",
    "- GSI: `status-index` on `status` attribute\n",
    "- Attributes: `user_id`, `name`, `status`, `age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 7\n",
    "\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "\n",
    "\n",
    "def query_users_by_status(table_name: str, status: str, min_age: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Query users by status and filter by minimum age.\n",
    "    \n",
    "    Uses a GSI on the status attribute for efficient querying,\n",
    "    then applies a filter expression for the age condition.\n",
    "    \n",
    "    Args:\n",
    "        table_name: Name of the DynamoDB table.\n",
    "        status: The status value to query for (e.g., 'active', 'inactive').\n",
    "        min_age: Minimum age filter (inclusive).\n",
    "        \n",
    "    Returns:\n",
    "        List of user items matching the criteria.\n",
    "    \"\"\"\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    table = dynamodb.Table(table_name)\n",
    "    \n",
    "    items = []\n",
    "    \n",
    "    try:\n",
    "        # Query using the GSI with a filter expression\n",
    "        response = table.query(\n",
    "            IndexName='status-index',\n",
    "            KeyConditionExpression=Key('status').eq(status),\n",
    "            FilterExpression=Attr('age').gte(min_age)\n",
    "        )\n",
    "        items.extend(response.get('Items', []))\n",
    "        \n",
    "        # Handle pagination\n",
    "        while 'LastEvaluatedKey' in response:\n",
    "            response = table.query(\n",
    "                IndexName='status-index',\n",
    "                KeyConditionExpression=Key('status').eq(status),\n",
    "                FilterExpression=Attr('age').gte(min_age),\n",
    "                ExclusiveStartKey=response['LastEvaluatedKey']\n",
    "            )\n",
    "            items.extend(response.get('Items', []))\n",
    "        \n",
    "        return items\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"Error querying table: {e.response['Error']['Message']}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.resource') as mock_resource:\n",
    "    mock_dynamodb = MagicMock()\n",
    "    mock_table = MagicMock()\n",
    "    mock_resource.return_value = mock_dynamodb\n",
    "    mock_dynamodb.Table.return_value = mock_table\n",
    "    \n",
    "    # Mock the query response\n",
    "    mock_table.query.return_value = {\n",
    "        'Items': [\n",
    "            {'user_id': '1', 'name': 'Alice', 'status': 'active', 'age': 30},\n",
    "            {'user_id': '2', 'name': 'Bob', 'status': 'active', 'age': 25},\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Test the function\n",
    "    users = query_users_by_status('Users', 'active', 21)\n",
    "    print(f\"Found {len(users)} users:\")\n",
    "    for user in users:\n",
    "        print(f\"  - {user['name']} (age: {user['age']})\")\n",
    "    \n",
    "    # Verify the query call\n",
    "    mock_table.query.assert_called()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Lambda and Messaging Services\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: Invoke Lambda Function (Intermediate)\n",
    "\n",
    "**Task:** Write a function called `invoke_lambda(function_name: str, payload: Dict, invocation_type: str = 'RequestResponse') -> Dict` that:\n",
    "1. Invokes an AWS Lambda function with the given payload\n",
    "2. Supports both synchronous (`RequestResponse`) and asynchronous (`Event`) invocation types\n",
    "3. For synchronous calls, parses and returns the response payload as a dictionary\n",
    "4. For async calls, returns a dictionary with the status code\n",
    "5. Handles errors and returns an error dictionary on failure\n",
    "\n",
    "**Return format:**\n",
    "- Success (sync): The parsed response payload\n",
    "- Success (async): `{'status': 'accepted', 'status_code': 202}`\n",
    "- Error: `{'error': 'error message'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 8\n",
    "\n",
    "def invoke_lambda(\n",
    "    function_name: str,\n",
    "    payload: Dict,\n",
    "    invocation_type: str = 'RequestResponse'\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Invoke an AWS Lambda function.\n",
    "    \n",
    "    Args:\n",
    "        function_name: Name or ARN of the Lambda function.\n",
    "        payload: Dictionary to send as the event payload.\n",
    "        invocation_type: 'RequestResponse' for sync, 'Event' for async.\n",
    "        \n",
    "    Returns:\n",
    "        For sync: The parsed response payload.\n",
    "        For async: Status dictionary with 'status' and 'status_code'.\n",
    "        On error: Dictionary with 'error' key.\n",
    "    \"\"\"\n",
    "    if invocation_type not in ['RequestResponse', 'Event']:\n",
    "        return {'error': f\"Invalid invocation type: {invocation_type}\"}\n",
    "    \n",
    "    lambda_client = boto3.client('lambda')\n",
    "    \n",
    "    try:\n",
    "        response = lambda_client.invoke(\n",
    "            FunctionName=function_name,\n",
    "            InvocationType=invocation_type,\n",
    "            Payload=json.dumps(payload)\n",
    "        )\n",
    "        \n",
    "        status_code = response['StatusCode']\n",
    "        \n",
    "        # Async invocation\n",
    "        if invocation_type == 'Event':\n",
    "            return {\n",
    "                'status': 'accepted',\n",
    "                'status_code': status_code\n",
    "            }\n",
    "        \n",
    "        # Sync invocation - parse the response\n",
    "        response_payload = response['Payload'].read().decode('utf-8')\n",
    "        \n",
    "        # Check for function error\n",
    "        if 'FunctionError' in response:\n",
    "            return {'error': f\"Function error: {response_payload}\"}\n",
    "        \n",
    "        # Parse and return the response\n",
    "        try:\n",
    "            return json.loads(response_payload)\n",
    "        except json.JSONDecodeError:\n",
    "            return {'response': response_payload}\n",
    "            \n",
    "    except ClientError as e:\n",
    "        return {'error': e.response['Error']['Message']}\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "from io import BytesIO\n",
    "\n",
    "with patch('boto3.client') as mock_client:\n",
    "    mock_lambda = MagicMock()\n",
    "    mock_client.return_value = mock_lambda\n",
    "    \n",
    "    # Test synchronous invocation\n",
    "    mock_response_payload = BytesIO(json.dumps({'result': 'success', 'data': [1, 2, 3]}).encode())\n",
    "    mock_lambda.invoke.return_value = {\n",
    "        'StatusCode': 200,\n",
    "        'Payload': mock_response_payload\n",
    "    }\n",
    "    \n",
    "    result = invoke_lambda('my-function', {'key': 'value'})\n",
    "    print(f\"Sync invocation result: {result}\")\n",
    "    \n",
    "    # Test async invocation\n",
    "    mock_lambda.invoke.return_value = {\n",
    "        'StatusCode': 202,\n",
    "        'Payload': BytesIO(b'')\n",
    "    }\n",
    "    \n",
    "    result = invoke_lambda('my-function', {'key': 'value'}, 'Event')\n",
    "    print(f\"Async invocation result: {result}\")\n",
    "    \n",
    "    # Test error handling\n",
    "    mock_lambda.invoke.side_effect = ClientError(\n",
    "        {'Error': {'Code': 'ResourceNotFoundException', 'Message': 'Function not found'}},\n",
    "        'invoke'\n",
    "    )\n",
    "    \n",
    "    result = invoke_lambda('non-existent-function', {})\n",
    "    print(f\"Error result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: SQS Message Queue Operations (Advanced)\n",
    "\n",
    "**Task:** Create a class called `SQSManager` that handles SQS operations:\n",
    "\n",
    "1. `__init__(self, queue_url: str)` - Initialize with queue URL\n",
    "2. `send_message(self, body: str, attributes: Optional[Dict] = None) -> Optional[str]` - Send a message, return message ID\n",
    "3. `send_batch(self, messages: List[Dict]) -> Dict` - Send up to 10 messages in a batch, return success/failure counts\n",
    "4. `receive_messages(self, max_count: int = 1, wait_time: int = 0) -> List[Dict]` - Receive messages with long polling support\n",
    "5. `delete_message(self, receipt_handle: str) -> bool` - Delete a processed message\n",
    "\n",
    "**Note:** The batch send should handle the 10-message limit and return `{'successful': count, 'failed': count}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 9\n",
    "\n",
    "import uuid\n",
    "\n",
    "\n",
    "class SQSManager:\n",
    "    \"\"\"\n",
    "    A manager class for SQS queue operations.\n",
    "    \n",
    "    Provides methods for sending, receiving, and deleting messages\n",
    "    from an SQS queue, including batch operations.\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_BATCH_SIZE = 10  # SQS limit for batch operations\n",
    "    \n",
    "    def __init__(self, queue_url: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the SQS manager.\n",
    "        \n",
    "        Args:\n",
    "            queue_url: The URL of the SQS queue.\n",
    "        \"\"\"\n",
    "        self.queue_url = queue_url\n",
    "        self.sqs_client = boto3.client('sqs')\n",
    "    \n",
    "    def send_message(\n",
    "        self,\n",
    "        body: str,\n",
    "        attributes: Optional[Dict] = None\n",
    "    ) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Send a single message to the queue.\n",
    "        \n",
    "        Args:\n",
    "            body: The message body (string).\n",
    "            attributes: Optional message attributes dictionary.\n",
    "            \n",
    "        Returns:\n",
    "            The message ID if successful, None otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            params = {\n",
    "                'QueueUrl': self.queue_url,\n",
    "                'MessageBody': body\n",
    "            }\n",
    "            \n",
    "            if attributes:\n",
    "                params['MessageAttributes'] = attributes\n",
    "            \n",
    "            response = self.sqs_client.send_message(**params)\n",
    "            return response.get('MessageId')\n",
    "            \n",
    "        except ClientError as e:\n",
    "            print(f\"Error sending message: {e.response['Error']['Message']}\")\n",
    "            return None\n",
    "    \n",
    "    def send_batch(self, messages: List[Dict]) -> Dict:\n",
    "        \"\"\"\n",
    "        Send multiple messages in a batch (up to 10).\n",
    "        \n",
    "        Args:\n",
    "            messages: List of message dictionaries with 'body' key\n",
    "                     and optional 'attributes' key.\n",
    "                     \n",
    "        Returns:\n",
    "            Dictionary with 'successful' and 'failed' counts.\n",
    "        \"\"\"\n",
    "        if not messages:\n",
    "            return {'successful': 0, 'failed': 0}\n",
    "        \n",
    "        # Limit to MAX_BATCH_SIZE messages\n",
    "        batch = messages[:self.MAX_BATCH_SIZE]\n",
    "        \n",
    "        entries = []\n",
    "        for i, msg in enumerate(batch):\n",
    "            entry = {\n",
    "                'Id': str(i),\n",
    "                'MessageBody': msg.get('body', '')\n",
    "            }\n",
    "            if 'attributes' in msg:\n",
    "                entry['MessageAttributes'] = msg['attributes']\n",
    "            entries.append(entry)\n",
    "        \n",
    "        try:\n",
    "            response = self.sqs_client.send_message_batch(\n",
    "                QueueUrl=self.queue_url,\n",
    "                Entries=entries\n",
    "            )\n",
    "            \n",
    "            successful = len(response.get('Successful', []))\n",
    "            failed = len(response.get('Failed', []))\n",
    "            \n",
    "            return {'successful': successful, 'failed': failed}\n",
    "            \n",
    "        except ClientError as e:\n",
    "            print(f\"Error in batch send: {e.response['Error']['Message']}\")\n",
    "            return {'successful': 0, 'failed': len(batch)}\n",
    "    \n",
    "    def receive_messages(\n",
    "        self,\n",
    "        max_count: int = 1,\n",
    "        wait_time: int = 0\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Receive messages from the queue.\n",
    "        \n",
    "        Args:\n",
    "            max_count: Maximum number of messages to receive (1-10).\n",
    "            wait_time: Long polling wait time in seconds (0-20).\n",
    "            \n",
    "        Returns:\n",
    "            List of message dictionaries with 'body', 'message_id',\n",
    "            and 'receipt_handle' keys.\n",
    "        \"\"\"\n",
    "        # Ensure valid ranges\n",
    "        max_count = min(max(1, max_count), 10)\n",
    "        wait_time = min(max(0, wait_time), 20)\n",
    "        \n",
    "        try:\n",
    "            response = self.sqs_client.receive_message(\n",
    "                QueueUrl=self.queue_url,\n",
    "                MaxNumberOfMessages=max_count,\n",
    "                WaitTimeSeconds=wait_time,\n",
    "                MessageAttributeNames=['All']\n",
    "            )\n",
    "            \n",
    "            messages = []\n",
    "            for msg in response.get('Messages', []):\n",
    "                messages.append({\n",
    "                    'body': msg['Body'],\n",
    "                    'message_id': msg['MessageId'],\n",
    "                    'receipt_handle': msg['ReceiptHandle'],\n",
    "                    'attributes': msg.get('MessageAttributes', {})\n",
    "                })\n",
    "            \n",
    "            return messages\n",
    "            \n",
    "        except ClientError as e:\n",
    "            print(f\"Error receiving messages: {e.response['Error']['Message']}\")\n",
    "            return []\n",
    "    \n",
    "    def delete_message(self, receipt_handle: str) -> bool:\n",
    "        \"\"\"\n",
    "        Delete a message from the queue.\n",
    "        \n",
    "        Args:\n",
    "            receipt_handle: The receipt handle from receive_message.\n",
    "            \n",
    "        Returns:\n",
    "            True if deletion was successful, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.sqs_client.delete_message(\n",
    "                QueueUrl=self.queue_url,\n",
    "                ReceiptHandle=receipt_handle\n",
    "            )\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            print(f\"Error deleting message: {e.response['Error']['Message']}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.client') as mock_client:\n",
    "    mock_sqs = MagicMock()\n",
    "    mock_client.return_value = mock_sqs\n",
    "    \n",
    "    manager = SQSManager('https://sqs.us-east-1.amazonaws.com/123456789012/my-queue')\n",
    "    \n",
    "    # Test send_message\n",
    "    mock_sqs.send_message.return_value = {'MessageId': 'msg-123'}\n",
    "    msg_id = manager.send_message('Hello, World!')\n",
    "    print(f\"Sent message ID: {msg_id}\")\n",
    "    \n",
    "    # Test send_batch\n",
    "    mock_sqs.send_message_batch.return_value = {\n",
    "        'Successful': [{'Id': '0'}, {'Id': '1'}],\n",
    "        'Failed': []\n",
    "    }\n",
    "    batch_result = manager.send_batch([\n",
    "        {'body': 'Message 1'},\n",
    "        {'body': 'Message 2'}\n",
    "    ])\n",
    "    print(f\"Batch result: {batch_result}\")\n",
    "    \n",
    "    # Test receive_messages\n",
    "    mock_sqs.receive_message.return_value = {\n",
    "        'Messages': [\n",
    "            {\n",
    "                'Body': 'Test message',\n",
    "                'MessageId': 'msg-456',\n",
    "                'ReceiptHandle': 'handle-789'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    messages = manager.receive_messages(max_count=5, wait_time=10)\n",
    "    print(f\"Received {len(messages)} message(s)\")\n",
    "    \n",
    "    # Test delete_message\n",
    "    result = manager.delete_message('handle-789')\n",
    "    print(f\"Delete result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Practical Patterns\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: Pagination Handler (Advanced)\n",
    "\n",
    "Many AWS operations return paginated results. Boto3 provides paginators to handle this.\n",
    "\n",
    "**Task:** Write a function called `list_all_s3_objects(bucket: str, prefix: str = '') -> List[Dict]` that:\n",
    "1. Uses a paginator to list ALL objects in an S3 bucket (handling pagination automatically)\n",
    "2. Filters by the given prefix (if provided)\n",
    "3. Returns a list of dictionaries with `key`, `size`, and `last_modified` for each object\n",
    "4. Handles empty buckets gracefully (returns empty list)\n",
    "\n",
    "**Hint:** Use `s3_client.get_paginator('list_objects_v2')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 10\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def list_all_s3_objects(bucket: str, prefix: str = '') -> List[Dict]:\n",
    "    \"\"\"\n",
    "    List all objects in an S3 bucket using pagination.\n",
    "    \n",
    "    Args:\n",
    "        bucket: Name of the S3 bucket.\n",
    "        prefix: Optional prefix to filter objects.\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with 'key', 'size', and 'last_modified'\n",
    "        for each object.\n",
    "    \"\"\"\n",
    "    s3_client = boto3.client('s3')\n",
    "    objects = []\n",
    "    \n",
    "    try:\n",
    "        # Create a paginator for list_objects_v2\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        \n",
    "        # Configure pagination parameters\n",
    "        page_config = {\n",
    "            'Bucket': bucket\n",
    "        }\n",
    "        if prefix:\n",
    "            page_config['Prefix'] = prefix\n",
    "        \n",
    "        # Iterate through all pages\n",
    "        for page in paginator.paginate(**page_config):\n",
    "            # Handle empty bucket or no matching objects\n",
    "            if 'Contents' not in page:\n",
    "                continue\n",
    "            \n",
    "            for obj in page['Contents']:\n",
    "                objects.append({\n",
    "                    'key': obj['Key'],\n",
    "                    'size': obj['Size'],\n",
    "                    'last_modified': obj['LastModified']\n",
    "                })\n",
    "        \n",
    "        return objects\n",
    "        \n",
    "    except ClientError as e:\n",
    "        print(f\"Error listing objects: {e.response['Error']['Message']}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.client') as mock_client:\n",
    "    mock_s3 = MagicMock()\n",
    "    mock_client.return_value = mock_s3\n",
    "    \n",
    "    # Create a mock paginator\n",
    "    mock_paginator = MagicMock()\n",
    "    mock_s3.get_paginator.return_value = mock_paginator\n",
    "    \n",
    "    # Mock paginated results (simulating 2 pages)\n",
    "    mock_paginator.paginate.return_value = [\n",
    "        {\n",
    "            'Contents': [\n",
    "                {'Key': 'file1.txt', 'Size': 1024, 'LastModified': datetime(2024, 1, 1)},\n",
    "                {'Key': 'file2.txt', 'Size': 2048, 'LastModified': datetime(2024, 1, 2)},\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            'Contents': [\n",
    "                {'Key': 'folder/file3.txt', 'Size': 512, 'LastModified': datetime(2024, 1, 3)},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Test listing all objects\n",
    "    objects = list_all_s3_objects('my-bucket')\n",
    "    print(f\"Found {len(objects)} objects:\")\n",
    "    for obj in objects:\n",
    "        print(f\"  - {obj['key']} ({obj['size']} bytes)\")\n",
    "    \n",
    "    # Test with prefix\n",
    "    mock_paginator.paginate.return_value = [\n",
    "        {\n",
    "            'Contents': [\n",
    "                {'Key': 'folder/file3.txt', 'Size': 512, 'LastModified': datetime(2024, 1, 3)},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    objects = list_all_s3_objects('my-bucket', prefix='folder/')\n",
    "    print(f\"\\nFound {len(objects)} objects with prefix 'folder/':\")\n",
    "    for obj in objects:\n",
    "        print(f\"  - {obj['key']}\")\n",
    "    \n",
    "    # Test empty bucket\n",
    "    mock_paginator.paginate.return_value = [{}]  # No Contents key\n",
    "    objects = list_all_s3_objects('empty-bucket')\n",
    "    print(f\"\\nEmpty bucket result: {objects}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11: Retry Logic with Exponential Backoff (Advanced)\n",
    "\n",
    "AWS operations can fail due to throttling or transient errors. Implementing proper retry logic is essential.\n",
    "\n",
    "**Task:** Write a decorator called `aws_retry` that:\n",
    "1. Retries a function up to `max_retries` times (default 3)\n",
    "2. Uses exponential backoff: wait time = `base_delay * (2 ** attempt)` seconds\n",
    "3. Only retries on specific exceptions: `ClientError` with throttling error codes (`Throttling`, `ThrottlingException`, `RequestLimitExceeded`)\n",
    "4. Re-raises the exception after all retries are exhausted\n",
    "5. Logs each retry attempt (print is fine for this exercise)\n",
    "\n",
    "**Usage example:**\n",
    "```python\n",
    "@aws_retry(max_retries=3, base_delay=1)\n",
    "def my_aws_operation():\n",
    "    # AWS code here\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 11\n",
    "\n",
    "import time\n",
    "from functools import wraps\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def aws_retry(max_retries: int = 3, base_delay: float = 1.0) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator for retrying AWS operations with exponential backoff.\n",
    "    \n",
    "    Only retries on throttling-related ClientError exceptions.\n",
    "    \n",
    "    Args:\n",
    "        max_retries: Maximum number of retry attempts.\n",
    "        base_delay: Base delay in seconds for exponential backoff.\n",
    "        \n",
    "    Returns:\n",
    "        Decorated function with retry logic.\n",
    "    \"\"\"\n",
    "    # Error codes that indicate throttling\n",
    "    THROTTLING_CODES = {\n",
    "        'Throttling',\n",
    "        'ThrottlingException',\n",
    "        'RequestLimitExceeded',\n",
    "        'ProvisionedThroughputExceededException',\n",
    "        'TooManyRequestsException'\n",
    "    }\n",
    "    \n",
    "    def decorator(func: Callable) -> Callable:\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_exception = None\n",
    "            \n",
    "            for attempt in range(max_retries + 1):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                    \n",
    "                except ClientError as e:\n",
    "                    error_code = e.response['Error']['Code']\n",
    "                    \n",
    "                    # Only retry on throttling errors\n",
    "                    if error_code not in THROTTLING_CODES:\n",
    "                        raise\n",
    "                    \n",
    "                    last_exception = e\n",
    "                    \n",
    "                    # If we've exhausted all retries, raise\n",
    "                    if attempt >= max_retries:\n",
    "                        print(f\"Max retries ({max_retries}) exhausted for {func.__name__}\")\n",
    "                        raise\n",
    "                    \n",
    "                    # Calculate wait time with exponential backoff\n",
    "                    wait_time = base_delay * (2 ** attempt)\n",
    "                    \n",
    "                    print(\n",
    "                        f\"Retry {attempt + 1}/{max_retries} for {func.__name__} \"\n",
    "                        f\"after {error_code}. Waiting {wait_time:.2f}s...\"\n",
    "                    )\n",
    "                    \n",
    "                    time.sleep(wait_time)\n",
    "            \n",
    "            # This shouldn't be reached, but just in case\n",
    "            if last_exception:\n",
    "                raise last_exception\n",
    "                \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "# Test the decorator\n",
    "call_count = 0\n",
    "\n",
    "@aws_retry(max_retries=3, base_delay=0.1)  # Short delay for testing\n",
    "def mock_throttled_operation():\n",
    "    \"\"\"Simulates an operation that gets throttled.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    \n",
    "    # Succeed on the 3rd attempt\n",
    "    if call_count < 3:\n",
    "        raise ClientError(\n",
    "            {'Error': {'Code': 'Throttling', 'Message': 'Rate exceeded'}},\n",
    "            'TestOperation'\n",
    "        )\n",
    "    return 'Success!'\n",
    "\n",
    "\n",
    "@aws_retry(max_retries=2, base_delay=0.1)\n",
    "def mock_always_fails():\n",
    "    \"\"\"Simulates an operation that always fails with throttling.\"\"\"\n",
    "    raise ClientError(\n",
    "        {'Error': {'Code': 'ThrottlingException', 'Message': 'Too many requests'}},\n",
    "        'TestOperation'\n",
    "    )\n",
    "\n",
    "\n",
    "@aws_retry(max_retries=3, base_delay=0.1)\n",
    "def mock_non_throttling_error():\n",
    "    \"\"\"Simulates a non-throttling error (should not retry).\"\"\"\n",
    "    raise ClientError(\n",
    "        {'Error': {'Code': 'AccessDenied', 'Message': 'Access Denied'}},\n",
    "        'TestOperation'\n",
    "    )\n",
    "\n",
    "\n",
    "# Test 1: Operation succeeds after retries\n",
    "print(\"Test 1: Operation with retries that eventually succeeds\")\n",
    "call_count = 0\n",
    "result = mock_throttled_operation()\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"Total calls: {call_count}\\n\")\n",
    "\n",
    "# Test 2: Operation fails after all retries\n",
    "print(\"Test 2: Operation that fails after all retries\")\n",
    "try:\n",
    "    mock_always_fails()\n",
    "except ClientError as e:\n",
    "    print(f\"Caught expected error: {e.response['Error']['Code']}\\n\")\n",
    "\n",
    "# Test 3: Non-throttling error (should not retry)\n",
    "print(\"Test 3: Non-throttling error (should not retry)\")\n",
    "try:\n",
    "    mock_non_throttling_error()\n",
    "except ClientError as e:\n",
    "    print(f\"Caught non-throttling error immediately: {e.response['Error']['Code']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12: Multi-Service Integration (Advanced)\n",
    "\n",
    "**Scenario:** You need to build a simple data pipeline that:\n",
    "1. Receives a file upload notification\n",
    "2. Processes the file metadata\n",
    "3. Stores results in DynamoDB\n",
    "4. Sends a notification when complete\n",
    "\n",
    "**Task:** Write a class called `S3EventProcessor` with the following methods:\n",
    "\n",
    "1. `__init__(self, dynamodb_table: str, sns_topic_arn: str)` - Initialize with DynamoDB table name and SNS topic ARN\n",
    "\n",
    "2. `process_s3_event(self, event: Dict) -> Dict` - Process an S3 event notification:\n",
    "   - Extract bucket name, object key, and size from the event\n",
    "   - Store metadata in DynamoDB (object_key as primary key, include bucket, size, processed_at timestamp)\n",
    "   - Publish a success notification to SNS\n",
    "   - Return a summary dict with status and processed object info\n",
    "\n",
    "3. `_store_metadata(self, metadata: Dict) -> bool` - Helper to store in DynamoDB\n",
    "\n",
    "4. `_send_notification(self, message: str, subject: str) -> bool` - Helper to publish to SNS\n",
    "\n",
    "**Sample S3 event structure (simplified):**\n",
    "```python\n",
    "{\n",
    "    'Records': [{\n",
    "        's3': {\n",
    "            'bucket': {'name': 'my-bucket'},\n",
    "            'object': {'key': 'path/to/file.txt', 'size': 1024}\n",
    "        }\n",
    "    }]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION for Question 12\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "class S3EventProcessor:\n",
    "    \"\"\"\n",
    "    Processes S3 events and stores metadata in DynamoDB with SNS notifications.\n",
    "    \n",
    "    This class demonstrates a common serverless pattern where S3 events\n",
    "    trigger processing that involves multiple AWS services.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dynamodb_table: str, sns_topic_arn: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the S3 event processor.\n",
    "        \n",
    "        Args:\n",
    "            dynamodb_table: Name of the DynamoDB table for storing metadata.\n",
    "            sns_topic_arn: ARN of the SNS topic for notifications.\n",
    "        \"\"\"\n",
    "        self.dynamodb_table = dynamodb_table\n",
    "        self.sns_topic_arn = sns_topic_arn\n",
    "        \n",
    "        # Initialize AWS clients\n",
    "        self.dynamodb = boto3.resource('dynamodb')\n",
    "        self.table = self.dynamodb.Table(dynamodb_table)\n",
    "        self.sns_client = boto3.client('sns')\n",
    "    \n",
    "    def process_s3_event(self, event: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Process an S3 event notification.\n",
    "        \n",
    "        Extracts file metadata from the event, stores it in DynamoDB,\n",
    "        and sends an SNS notification.\n",
    "        \n",
    "        Args:\n",
    "            event: S3 event notification dictionary.\n",
    "            \n",
    "        Returns:\n",
    "            Summary dictionary with:\n",
    "            - status: 'success' or 'error'\n",
    "            - processed_objects: List of processed object info\n",
    "            - error: Error message (if status is 'error')\n",
    "        \"\"\"\n",
    "        processed_objects = []\n",
    "        errors = []\n",
    "        \n",
    "        try:\n",
    "            records = event.get('Records', [])\n",
    "            \n",
    "            if not records:\n",
    "                return {\n",
    "                    'status': 'error',\n",
    "                    'error': 'No records found in event',\n",
    "                    'processed_objects': []\n",
    "                }\n",
    "            \n",
    "            for record in records:\n",
    "                try:\n",
    "                    # Extract S3 information\n",
    "                    s3_info = record.get('s3', {})\n",
    "                    bucket_name = s3_info.get('bucket', {}).get('name')\n",
    "                    object_key = s3_info.get('object', {}).get('key')\n",
    "                    object_size = s3_info.get('object', {}).get('size', 0)\n",
    "                    \n",
    "                    if not bucket_name or not object_key:\n",
    "                        errors.append(f\"Missing bucket or object key in record\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Create metadata record\n",
    "                    timestamp = datetime.now(timezone.utc).isoformat()\n",
    "                    metadata = {\n",
    "                        'object_key': object_key,\n",
    "                        'bucket': bucket_name,\n",
    "                        'size': object_size,\n",
    "                        'processed_at': timestamp\n",
    "                    }\n",
    "                    \n",
    "                    # Store metadata in DynamoDB\n",
    "                    if not self._store_metadata(metadata):\n",
    "                        errors.append(f\"Failed to store metadata for {object_key}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Send notification\n",
    "                    notification_message = (\n",
    "                        f\"Successfully processed file: {object_key}\\n\"\n",
    "                        f\"Bucket: {bucket_name}\\n\"\n",
    "                        f\"Size: {object_size} bytes\\n\"\n",
    "                        f\"Processed at: {timestamp}\"\n",
    "                    )\n",
    "                    self._send_notification(\n",
    "                        message=notification_message,\n",
    "                        subject=f\"S3 File Processed: {object_key}\"\n",
    "                    )\n",
    "                    \n",
    "                    processed_objects.append({\n",
    "                        'bucket': bucket_name,\n",
    "                        'key': object_key,\n",
    "                        'size': object_size\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    errors.append(f\"Error processing record: {str(e)}\")\n",
    "            \n",
    "            # Determine overall status\n",
    "            if errors and not processed_objects:\n",
    "                return {\n",
    "                    'status': 'error',\n",
    "                    'error': '; '.join(errors),\n",
    "                    'processed_objects': []\n",
    "                }\n",
    "            elif errors:\n",
    "                return {\n",
    "                    'status': 'partial_success',\n",
    "                    'processed_objects': processed_objects,\n",
    "                    'errors': errors\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'status': 'success',\n",
    "                    'processed_objects': processed_objects\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'processed_objects': []\n",
    "            }\n",
    "    \n",
    "    def _store_metadata(self, metadata: Dict) -> bool:\n",
    "        \"\"\"\n",
    "        Store file metadata in DynamoDB.\n",
    "        \n",
    "        Args:\n",
    "            metadata: Dictionary containing file metadata.\n",
    "            \n",
    "        Returns:\n",
    "            True if storage was successful, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.table.put_item(Item=metadata)\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            print(f\"DynamoDB error: {e.response['Error']['Message']}\")\n",
    "            return False\n",
    "    \n",
    "    def _send_notification(self, message: str, subject: str) -> bool:\n",
    "        \"\"\"\n",
    "        Publish a notification to SNS.\n",
    "        \n",
    "        Args:\n",
    "            message: The notification message body.\n",
    "            subject: The notification subject.\n",
    "            \n",
    "        Returns:\n",
    "            True if notification was sent successfully, False otherwise.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.sns_client.publish(\n",
    "                TopicArn=self.sns_topic_arn,\n",
    "                Message=message,\n",
    "                Subject=subject\n",
    "            )\n",
    "            return True\n",
    "        except ClientError as e:\n",
    "            print(f\"SNS error: {e.response['Error']['Message']}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# Test with mocking\n",
    "with patch('boto3.resource') as mock_resource, \\\n",
    "     patch('boto3.client') as mock_client:\n",
    "    \n",
    "    # Setup mocks\n",
    "    mock_dynamodb = MagicMock()\n",
    "    mock_table = MagicMock()\n",
    "    mock_sns = MagicMock()\n",
    "    \n",
    "    mock_resource.return_value = mock_dynamodb\n",
    "    mock_dynamodb.Table.return_value = mock_table\n",
    "    mock_client.return_value = mock_sns\n",
    "    \n",
    "    # Create processor\n",
    "    processor = S3EventProcessor(\n",
    "        dynamodb_table='FileMetadata',\n",
    "        sns_topic_arn='arn:aws:sns:us-east-1:123456789012:file-notifications'\n",
    "    )\n",
    "    \n",
    "    # Test S3 event\n",
    "    test_event = {\n",
    "        'Records': [\n",
    "            {\n",
    "                's3': {\n",
    "                    'bucket': {'name': 'my-bucket'},\n",
    "                    'object': {'key': 'uploads/document.pdf', 'size': 102400}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                's3': {\n",
    "                    'bucket': {'name': 'my-bucket'},\n",
    "                    'object': {'key': 'uploads/image.png', 'size': 51200}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    result = processor.process_s3_event(test_event)\n",
    "    \n",
    "    print(f\"Processing result:\")\n",
    "    print(f\"  Status: {result['status']}\")\n",
    "    print(f\"  Processed objects: {len(result['processed_objects'])}\")\n",
    "    for obj in result['processed_objects']:\n",
    "        print(f\"    - {obj['key']} ({obj['size']} bytes)\")\n",
    "    \n",
    "    # Verify DynamoDB was called\n",
    "    assert mock_table.put_item.call_count == 2, \"Should store 2 items\"\n",
    "    \n",
    "    # Verify SNS was called\n",
    "    assert mock_sns.publish.call_count == 2, \"Should send 2 notifications\"\n",
    "    \n",
    "    print(\"\\nAll assertions passed!\")\n",
    "    \n",
    "    # Test with empty event\n",
    "    empty_result = processor.process_s3_event({'Records': []})\n",
    "    print(f\"\\nEmpty event result: {empty_result['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## End of Test - SOLUTIONS\n",
    "\n",
    "This solutions notebook demonstrates:\n",
    "- Proper type hints in all function signatures\n",
    "- Comprehensive error handling for AWS operations\n",
    "- Clear, readable code following PEP 8\n",
    "- Effective use of mocking for testing AWS code without real credentials\n",
    "- Best practices for boto3 usage including pagination and retry logic\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 4,
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
